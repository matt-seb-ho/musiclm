{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Unconditioned Symbolic Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/matt/miniconda3/envs/audiocraft/lib/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matt/audiocraft\n",
      "\u001b[2mUsing Python 3.9.21 environment at: /data/matt/miniconda3/envs/audiocraft\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m152 packages\u001b[0m \u001b[2min 1.03s\u001b[0m\u001b[0m                                       \u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m     0 B/5.38 KiB                      \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 7ms\u001b[0m\u001b[0m                                                    \u001b[1A\n",
      "\u001b[2mUninstalled \u001b[1m15 packages\u001b[0m \u001b[2min 250ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m107 packages\u001b[0m \u001b[2min 453ms\u001b[0m\u001b[0m                             \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiofiles\u001b[0m\u001b[2m==23.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maudiocraft\u001b[0m\u001b[2m==1.4.0a2 (from file:///home/matt/audiocraft)\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mav\u001b[0m\u001b[2m==11.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mblis\u001b[0m\u001b[2m==0.7.11\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcatalogue\u001b[0m\u001b[2m==2.0.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.1.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcloudpathlib\u001b[0m\u001b[2m==0.21.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcolorlog\u001b[0m\u001b[2m==6.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mconfection\u001b[0m\u001b[2m==0.1.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcontourpy\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcycler\u001b[0m\u001b[2m==0.12.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcymem\u001b[0m\u001b[2m==2.0.11\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdemucs\u001b[0m\u001b[2m==4.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdocopt\u001b[0m\u001b[2m==0.6.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1meinops\u001b[0m\u001b[2m==0.8.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mencodec\u001b[0m\u001b[2m==0.1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfastapi\u001b[0m\u001b[2m==0.115.12\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mffmpy\u001b[0m\u001b[2m==0.6.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mflashy\u001b[0m\u001b[2m==0.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfonttools\u001b[0m\u001b[2m==4.58.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgradio\u001b[0m\u001b[2m==4.44.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgradio-client\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mh11\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhf-xet\u001b[0m\u001b[2m==1.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpcore\u001b[0m\u001b[2m==1.0.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpx\u001b[0m\u001b[2m==0.28.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.32.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhydra-colorlog\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhydra-core\u001b[0m\u001b[2m==1.3.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mimportlib-resources\u001b[0m\u001b[2m==6.5.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjulius\u001b[0m\u001b[2m==0.2.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mkiwisolver\u001b[0m\u001b[2m==1.4.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlameenc\u001b[0m\u001b[2m==1.8.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangcodes\u001b[0m\u001b[2m==3.5.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlanguage-data\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlightning-utilities\u001b[0m\u001b[2m==0.14.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarisa-trie\u001b[0m\u001b[2m==1.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkdown-it-py\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==2.1.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmatplotlib\u001b[0m\u001b[2m==3.9.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmdurl\u001b[0m\u001b[2m==0.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmurmurhash\u001b[0m\u001b[2m==1.0.13\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnum2words\u001b[0m\u001b[2m==0.5.14\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.6.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.1.3.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.6.80\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.1.105\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.1.105\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.1.105\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.5.1.17\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==8.9.2.26\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.0.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.0.2.54\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.7.77\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.2.106\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.4.5.107\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.4.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.1.0.106\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.26.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.18.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.1.105\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopenunmix\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1morjson\u001b[0m\u001b[2m==3.10.18\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.2.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpesq\u001b[0m\u001b[2m==0.0.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==10.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpreshed\u001b[0m\u001b[2m==3.0.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==6.31.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.11.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.33.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydub\u001b[0m\u001b[2m==0.25.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyparsing\u001b[0m\u001b[2m==3.2.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpystoi\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-multipart\u001b[0m\u001b[2m==0.0.20\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpytz\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mregex\u001b[0m\u001b[2m==2024.11.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrich\u001b[0m\u001b[2m==14.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mruff\u001b[0m\u001b[2m==0.11.12\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msafetensors\u001b[0m\u001b[2m==0.5.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msemantic-version\u001b[0m\u001b[2m==2.10.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msentencepiece\u001b[0m\u001b[2m==0.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mshellingham\u001b[0m\u001b[2m==1.5.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msmart-open\u001b[0m\u001b[2m==7.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msniffio\u001b[0m\u001b[2m==1.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mspacy\u001b[0m\u001b[2m==3.7.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mspacy-legacy\u001b[0m\u001b[2m==3.0.12\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mspacy-loggers\u001b[0m\u001b[2m==1.0.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msrsly\u001b[0m\u001b[2m==2.5.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mstarlette\u001b[0m\u001b[2m==0.46.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mthinc\u001b[0m\u001b[2m==8.2.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.21.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtomlkit\u001b[0m\u001b[2m==0.12.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorchaudio\u001b[0m\u001b[2m==2.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorchdata\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorchdiffeq\u001b[0m\u001b[2m==0.2.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorchmetrics\u001b[0m\u001b[2m==1.7.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorchtext\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.52.4\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==2.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyper\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-inspection\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtzdata\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1muvicorn\u001b[0m\u001b[2m==0.34.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwasabi\u001b[0m\u001b[2m==1.1.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mweasel\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwebsockets\u001b[0m\u001b[2m==12.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwrapt\u001b[0m\u001b[2m==1.17.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mxformers\u001b[0m\u001b[2m==0.0.22.post7\u001b[0m\n",
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`spacy==3.7.6` is yanked (reason: \"Incorrect compatibility for transformer models\")\u001b[0m\n",
      "\u001b[2mUsing Python 3.9.21 environment at: /data/matt/miniconda3/envs/audiocraft\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m5 packages\u001b[0m \u001b[2min 8ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/facebookresearch/audiocraft.git\n",
    "# %cd udiocraft\n",
    "# !uv pip install -e .\n",
    "# !uv pip install dora-search numba librosa mido PyYAML datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matt/audiocraft\n"
     ]
    }
   ],
   "source": [
    "%cd /home/matt/audiocraft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/matt/miniconda3/envs/audiocraft/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "import librosa\n",
    "import mido\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import yaml\n",
    "from datasets import Dataset, load_dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dora directory: /tmp/audiocraft_matt\n"
     ]
    }
   ],
   "source": [
    "from audiocraft import train\n",
    "from audiocraft.data.audio import audio_write\n",
    "from audiocraft.models import MusicGen\n",
    "from audiocraft.utils import export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TMPDIR\"] = \"/data/matt/tmp\"\n",
    "PROJECT_DATA_DIR = Path(\"/data/matt/cse253a2\")\n",
    "PROJECT_DATA_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## slakh dataset preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLAKH_DIR = Path(\"/data/matt/slakh2100_flac_redux\")\n",
    "BABYSLAKH_DIR = Path(\"/data/matt/babyslakh_16k\")\n",
    "TRACK_ID_PATTERN = re.compile(r\"slakh2100_flac_redux\\/(.+?)\\/Track(\\d+)\\/mix\\.flac$\")\n",
    "BABYSLAKH_TRACK_ID_PATTERN = re.compile(r\"\\/Track(\\d+)\\/mix\\.wav$\")\n",
    "DEFAULT_INSTRUMENTS = [\"Piano\", \"Bass\", \"Guitar\", \"Drums\"]\n",
    "DEFAULT_MIDI_TEMPO = 500000\n",
    "BABYSLAKH_SAMPLE_RATE = 16000\n",
    "SLAKH_SAMPLE_RATE = 44100\n",
    "\n",
    "\n",
    "def get_babyslakh_paths(root_dir: Path = BABYSLAKH_DIR) -> List[Path]:\n",
    "    return [\n",
    "        root_dir / track_dir / \"mix.wav\"\n",
    "        for track_dir in os.listdir(root_dir)\n",
    "        if \"Track\" in track_dir and (root_dir / track_dir / \"mix.wav\").exists()\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_slakh_paths(root_dir: Path = SLAKH_DIR) -> List[Path]:\n",
    "    splits = [\"train\", \"test\", \"validation\"]\n",
    "    paths = []\n",
    "    for split_dir in os.listdir(root_dir):\n",
    "        if split_dir not in splits:\n",
    "            continue\n",
    "        split_path = root_dir / split_dir\n",
    "        for track_dir in os.listdir(split_path):\n",
    "            mix_path = split_path / track_dir / \"mix.flac\"\n",
    "            if \"Track\" in track_dir and mix_path.exists():\n",
    "                paths.append(mix_path)\n",
    "    return paths\n",
    "\n",
    "\n",
    "def extract_sample_id(path: str, is_babyslakh: bool = False) -> Tuple[str, str]:\n",
    "    pattern = BABYSLAKH_TRACK_ID_PATTERN if is_babyslakh else TRACK_ID_PATTERN\n",
    "    match = pattern.search(path)\n",
    "    if match is None:\n",
    "        raise ValueError(f\"Track ID not found in path: {path}\")\n",
    "    if is_babyslakh:\n",
    "        coin_flip = random.randint(0, 1)\n",
    "        split = \"test\" if coin_flip == 0 else \"train\"\n",
    "        return split, match.group(1)\n",
    "    return match.group(1), match.group(2)\n",
    "\n",
    "\n",
    "def get_midi_program_names(track_directory: Path) -> List[str]:\n",
    "    try:\n",
    "        with open(track_directory / \"metadata.yaml\", \"r\") as f:\n",
    "            metadata = yaml.safe_load(f)\n",
    "        program_names = []\n",
    "        for stem_id, stem_info in metadata[\"stems\"].items():\n",
    "            if \"midi_program_name\" in stem_info:\n",
    "                program_names.append(stem_info[\"midi_program_name\"])\n",
    "        return program_names\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load metadata for {track_directory}: {e}\")\n",
    "        return DEFAULT_INSTRUMENTS\n",
    "\n",
    "\n",
    "def get_tempo(mid):\n",
    "    for track in mid.tracks:\n",
    "        for msg in track:\n",
    "            if msg.type == \"set_tempo\":\n",
    "                return msg.tempo\n",
    "    return DEFAULT_MIDI_TEMPO\n",
    "\n",
    "\n",
    "def get_bpm(track_directory: Path) -> int:\n",
    "    try:\n",
    "        mid = mido.MidiFile(track_directory / \"all_src.mid\")\n",
    "        tempo = get_tempo(mid)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to get tempo for {track_directory}: {e}\")\n",
    "        tempo = DEFAULT_MIDI_TEMPO\n",
    "    return round(mido.tempo2bpm(tempo))\n",
    "\n",
    "\n",
    "def get_condition_data(slakh_paths, is_babyslakh: bool = False) -> Dict[str, Any]:\n",
    "    condition_data = defaultdict(dict)\n",
    "    for audio_path in tqdm(slakh_paths):\n",
    "        track_directory = audio_path.parent\n",
    "        path_str = str(audio_path)\n",
    "        split, track_id = extract_sample_id(path_str, is_babyslakh=is_babyslakh)\n",
    "        if split == \"train\":\n",
    "            split = \"training\"\n",
    "        try:\n",
    "            bpm = get_bpm(track_directory)\n",
    "            program_names = get_midi_program_names(track_directory)\n",
    "            condition_data[split][track_id] = {\n",
    "                \"bpm\": bpm,\n",
    "                \"midi_program_names\": program_names,\n",
    "                \"track_path\": str(audio_path),\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Failed on {audio_path}: {e}\")\n",
    "    return condition_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1710 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1710/1710 [04:49<00:00,  5.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# babyslakh_paths = get_babyslakh_paths()\n",
    "# condition_data = get_condition_data(babyslakh_paths, is_babyslakh=True)\n",
    "slakh_paths = get_slakh_paths()\n",
    "condition_data = get_condition_data(slakh_paths, is_babyslakh=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/data/matt/all_conditions.json\", \"w\") as f:\n",
    "    json.dump(condition_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create .jsonl from the extracted features, make a train/test split, and save in the right place.\n",
    "\n",
    "\n",
    "def write_jsonl(data: list[dict], file_path: Path) -> None:\n",
    "    with open(file_path, \"w\") as f:\n",
    "        for entry in data:\n",
    "            f.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "\n",
    "def prepare_slakh_data(\n",
    "    split_directories: dict[str, Path],\n",
    "    sr: int = SLAKH_SAMPLE_RATE,\n",
    "    file_extension: str = \"flac\",\n",
    "):\n",
    "    for directory in split_directories.values():\n",
    "        directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    data_lists = {\n",
    "        \"train\": [],\n",
    "        \"test\": [],\n",
    "        \"validation\": [],\n",
    "    }\n",
    "\n",
    "    for split, split_data in condition_data.items():\n",
    "        if split == \"training\":\n",
    "            split = \"train\"\n",
    "        for track_id, track_info in tqdm(split_data.items(), total=len(split_data)):\n",
    "            path = Path(track_info[\"track_path\"])\n",
    "            y, sr = librosa.load(path)\n",
    "            chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "            key = np.argmax(np.sum(chroma, axis=1))\n",
    "            length = librosa.get_duration(y=y, sr=sr)\n",
    "            entry = {\n",
    "                \"key\": str(key),\n",
    "                \"sample_rate\": sr,\n",
    "                \"file_extension\": file_extension,\n",
    "                \"description\": \"\",\n",
    "                \"keywords\": \"\",\n",
    "                \"duration\": length,\n",
    "                \"bpm\": track_info[\"bpm\"],\n",
    "                \"genre\": \"\",\n",
    "                \"title\": \"\",\n",
    "                \"name\": \"\",\n",
    "                \"instrument\": \", \".join(track_info[\"midi_program_names\"]),\n",
    "                \"moods\": [],\n",
    "                \"path\": str(path),\n",
    "            }\n",
    "            data_lists[split].append(entry)\n",
    "\n",
    "    # print split sizes\n",
    "    for split, data in data_lists.items():\n",
    "        print(f\"{split} size: {len(data)}\")\n",
    "        write_jsonl(data, split_directories[split] / \"data.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1289/1289 [23:11<00:00,  1.08s/it]\n",
      "100%|██████████| 270/270 [04:49<00:00,  1.07s/it]\n",
      "100%|██████████| 151/151 [02:51<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 1289\n",
      "test size: 151\n",
      "validation size: 270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "music_gen_slakh_directory = Path(\"/data/matt/music_gen_slakh\")\n",
    "split_directories = {\n",
    "    \"train\": music_gen_slakh_directory / \"train\",\n",
    "    \"test\": music_gen_slakh_directory / \"test\",\n",
    "    \"validation\": music_gen_slakh_directory / \"validation\",\n",
    "}\n",
    "prepare_slakh_data(\n",
    "    split_directories,\n",
    "    sr=SLAKH_SAMPLE_RATE,\n",
    "    file_extension=\"flac\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run training with dora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train', 'validation', 'test']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(music_gen_slakh_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_command = \"\"\"\\\n",
    "CUDA_VISIBLE_DEVICES=4,5,6,7 dora -P audiocraft run \\\n",
    "  solver=musicgen/musicgen_base_32khz \\\n",
    "  +model.lm.model_scale=small \\\n",
    "  continue_from=//pretrained/facebook/musicgen-small \\\n",
    "  conditioner=text2music \\\n",
    "  dset=audio/babyslakh \\\n",
    "  dataset.num_workers=2 \\\n",
    "  dataset.valid.num_samples=1 \\\n",
    "  dataset.batch_size=2 \\\n",
    "  schedule.cosine.warmup=8 \\\n",
    "  optim.optimizer=adamw \\\n",
    "  optim.lr=1e-4 \\\n",
    "  optim.epochs=2 \\\n",
    "  optim.updates_per_epoch=100 \\\n",
    "  optim.adam.weight_decay=0.01 \\\n",
    "  generate.lm.prompted_samples=False \\\n",
    "  generate.lm.gen_gt_samples=True\n",
    "\"\"\"\n",
    "\n",
    "command = \"\"\"\\\n",
    "CUDA_VISIBLE_DEVICES=4,5,6,7 dora -P audiocraft run \\\n",
    "  solver=musicgen/musicgen_base_32khz \\\n",
    "  +model.lm.model_scale=small \\\n",
    "  continue_from=//pretrained/facebook/musicgen-small \\\n",
    "  conditioner=text2music \\\n",
    "  dset=audio/slakh \\\n",
    "  dataset.num_workers=4 \\\n",
    "  dataset.valid.num_samples=32 \\\n",
    "  dataset.batch_size=4 \\\n",
    "  schedule.cosine.warmup=8 \\\n",
    "  optim.optimizer=adamw \\\n",
    "  optim.lr=1e-4 \\\n",
    "  optim.epochs=1 \\\n",
    "  optim.updates_per_epoch=1000 \\\n",
    "  optim.adam.weight_decay=0.01 \\\n",
    "  generate.lm.prompted_samples=False \\\n",
    "  generate.lm.gen_gt_samples=True\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "Dora directory: /tmp/audiocraft_matt\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/matt/miniconda3/envs/cse253/bin/dora\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/dora/__main__.py\", line 170, in main\n",
      "    args.action(args, main)\n",
      "  File \"/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/dora/run.py\", line 51, in run_action\n",
      "    xp = main.get_xp(args.argv)\n",
      "  File \"/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/dora/hydra.py\", line 190, in get_xp\n",
      "    delta += self._get_delta(base, cfg)\n",
      "  File \"/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/dora/hydra.py\", line 297, in _get_delta\n",
      "    for diff in _compare_config(init, other):\n",
      "  File \"/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/dora/hydra.py\", line 75, in _compare_config\n",
      "    yield from _compare_config(ref_value, other_value, path)\n",
      "  File \"/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/dora/hydra.py\", line 67, in _compare_config\n",
      "    ref_value = ref[key]\n",
      "  File \"/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/omegaconf/dictconfig.py\", line 375, in __getitem__\n",
      "    self._format_and_raise(key=key, value=None, cause=e)\n",
      "  File \"/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/omegaconf/base.py\", line 231, in _format_and_raise\n",
      "    format_and_raise(\n",
      "  File \"/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/omegaconf/_utils.py\", line 899, in format_and_raise\n",
      "    _raise(ex, cause)\n",
      "  File \"/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/omegaconf/_utils.py\", line 797, in _raise\n",
      "    raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace\n",
      "  File \"/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/omegaconf/dictconfig.py\", line 369, in __getitem__\n",
      "    return self._get_impl(key=key, default_value=_DEFAULT_MARKER_)\n",
      "  File \"/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/omegaconf/dictconfig.py\", line 451, in _get_impl\n",
      "    return self._resolve_with_default(\n",
      "  File \"/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/omegaconf/basecontainer.py\", line 96, in _resolve_with_default\n",
      "    raise MissingMandatoryValue(\"Missing mandatory value: $FULL_KEY\")\n",
      "omegaconf.errors.MissingMandatoryValue: Missing mandatory value: dataset.batch_size\n",
      "    full_key: dataset.batch_size\n",
      "    object_type=dict\n",
      "/bin/bash: line 2: model/lm/model_scale=small: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original (tmp has since been set to /data/matt/tmp)\n",
    "# samples_dir = Path(\"/tmp/audiocraft_matt/xps/ed9b1b62/samples\")\n",
    "# baby training run\n",
    "# sig = \"ed9b1b62\"\n",
    "sig = \"12c4508d\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export fine-tuned model params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_dir = Path(\"/data/matt/mg_checkpoints\")\n",
    "v1_checkpoints_dir = checkpoints_dir / \"v1/finetune\"\n",
    "v2_checkpoints_dir = checkpoints_dir / \"v2/finetune\"\n",
    "checkpoints_dir = v2_checkpoints_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dora directory: /tmp/audiocraft_matt\n"
     ]
    }
   ],
   "source": [
    "# Exporting .bin files from a training run:\n",
    "\n",
    "\n",
    "sig = \"ed9b1b62\"\n",
    "\n",
    "# from https://github.com/facebookresearch/audiocraft/blob/main/docs/MUSICGEN.md#importing--exporting-models\n",
    "xp = train.main.get_xp_from_sig(sig)\n",
    "checkpoints_dir.mkdir(parents=True, exist_ok=True)\n",
    "export.export_lm(xp.folder / \"checkpoint.th\", checkpoints_dir / \"state_dict.bin\")\n",
    "export.export_pretrained_compression_model(\n",
    "    \"facebook/encodec_32khz\", checkpoints_dir / \"compression_state_dict.bin\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_DIR = Path(\"/data/matt/mg_checkpoints\")\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def export_model_checkpoint(sig: str, ckpt_d: Path = CKPT_DIR):\n",
    "    ckpt_d.mkdir(parents=True, exist_ok=True)\n",
    "    xp = train.main.get_xp_from_sig(sig)\n",
    "    export.export_lm(xp.folder / \"checkpoint.th\", ckpt_d / \"state_dict.bin\")\n",
    "    export.export_pretrained_compression_model(\n",
    "        \"facebook/encodec_32khz\",\n",
    "        ckpt_d / \"compression_state_dict.bin\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest (monday midnight) slakh run\n",
    "slakh_scaled_sig = \"f8f7a1d3\"\n",
    "slakh_scaled_ckpt = Path(\"/data/matt/mg_checkpoints/slakh_scaled\")\n",
    "export_model_checkpoint(\n",
    "    sig=\"f8f7a1d3\",\n",
    "    ckpt_d=slakh_scaled_ckpt,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up reference directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create slakh test split reference (st_ref)\n",
    "slakh_test_dir = SLAKH_DIR / \"test\"\n",
    "slakh_reference_dir = PROJECT_DATA_DIR / \"slakh/reference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_slakh_reference_dir(\n",
    "    reference_dir: Path,\n",
    "    num_tracks: int = 32,\n",
    "    track_length: int = 16,\n",
    ") -> list[str]:\n",
    "    reference_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tracks_copied = 0\n",
    "    track_ids = []\n",
    "    for track_dir in os.listdir(slakh_test_dir):\n",
    "        if \"Track\" not in track_dir:\n",
    "            continue\n",
    "        mix_flac = slakh_test_dir / track_dir / \"mix.flac\"\n",
    "        if not mix_flac.exists():\n",
    "            continue\n",
    "        audio, original_sr = librosa.load(mix_flac, sr=None, mono=False)\n",
    "        resampled = librosa.resample(audio, orig_sr=original_sr, target_sr=32000)\n",
    "        # cut it down to the first `track_length` seconds\n",
    "        if resampled.ndim == 1:\n",
    "            resampled = resampled[: track_length * 32000]\n",
    "        elif resampled.ndim == 2:\n",
    "            resampled = resampled[:, : track_length * 32000]\n",
    "            # librosa returns (channels, samples), sf expects (samples, channels)\n",
    "            resampled = resampled.T\n",
    "        _, track_id = extract_sample_id(str(mix_flac))\n",
    "        destination = reference_dir / f\"track{track_id}.wav\"\n",
    "        sf.write(destination, resampled, samplerate=32000)\n",
    "        tracks_copied += 1\n",
    "        track_ids.append(str(track_id))\n",
    "        if tracks_copied >= num_tracks:\n",
    "            break\n",
    "    return track_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_track_ids = create_slakh_reference_dir(slakh_reference_dir, num_tracks=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "slakh_og_metadata_path = PROJECT_DATA_DIR / \"slakh/original_metadata.json\"\n",
    "if slakh_og_metadata_path.exists():\n",
    "    with open(slakh_og_metadata_path, \"r\") as f:\n",
    "        # Load existing metadata\n",
    "        original_metadata = json.load(f)\n",
    "    condition_data = original_metadata\n",
    "else:\n",
    "    condition_data = get_condition_data(\n",
    "        get_slakh_paths(SLAKH_DIR),\n",
    "        is_babyslakh=False,\n",
    "    )\n",
    "    with open(PROJECT_DATA_DIR / \"slakh/original_metadata.json\", \"w\") as f:\n",
    "        json.dump(condition_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(bpm: int, midi_program_names: list[str]) -> str:\n",
    "    instruments = \", \".join(midi_program_names)\n",
    "    return f\"{bpm} BPM with {instruments}.\"\n",
    "\n",
    "\n",
    "def create_reference_condition_data(\n",
    "    condition_data: dict[str, Any],\n",
    "    reference_dir: Path,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Create a dictionary with reference condition data.\"\"\"\n",
    "    reference_condition_data = {}\n",
    "    for track_id, info in condition_data[\"test\"].items():\n",
    "        file_path = reference_dir / f\"track{track_id}.wav\"\n",
    "        if not file_path.exists():\n",
    "            continue\n",
    "        reference_condition_data[track_id] = {\n",
    "            \"bpm\": info[\"bpm\"],\n",
    "            \"midi_program_names\": info[\"midi_program_names\"],\n",
    "            \"track_path\": str(file_path),\n",
    "            \"prompt\": format_prompt(info[\"bpm\"], info[\"midi_program_names\"]),\n",
    "        }\n",
    "    return reference_condition_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcd = create_reference_condition_data(\n",
    "    condition_data,\n",
    "    slakh_reference_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate New Samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select GPU\n",
    "torch.cuda.set_device(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/audiocraft/audiocraft/models/musicgen.py:83: UserWarning: MusicGen pretrained model relying on deprecated checkpoint mapping. Please use full pre-trained id instead: facebook/musicgen-small\n",
      "  warnings.warn(\n",
      "/data/matt/miniconda3/envs/audiocraft/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "# load in baseline model\n",
    "baseline = MusicGen.get_pretrained(\"small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_slakh = MusicGen.get_pretrained(checkpoints_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATED_AUDIO_DIR = Path(\"/data/matt/mg_generated_audio\")\n",
    "BASELINE_OUTPUT_DIR = GENERATED_AUDIO_DIR / \"baseline\"\n",
    "FINETUNE_OUTPUT_DIR = GENERATED_AUDIO_DIR / \"finetune\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _resample_and_overwrite(\n",
    "    audio_file: Path,\n",
    "    target_sr: Optional[int] = None,\n",
    ") -> None:\n",
    "    if target_sr is None:\n",
    "        return\n",
    "    y, sr = librosa.load(audio_file, sr=None)\n",
    "    audio = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
    "    if audio.ndim == 2:\n",
    "        audio = audio.T\n",
    "    # overwrite the file with the resampled audio\n",
    "    sf.write(audio_file, audio, samplerate=target_sr)\n",
    "\n",
    "\n",
    "def unconditional_generate_wrapper(\n",
    "    model: MusicGen,\n",
    "    duration: int = 16,\n",
    "    num_samples: int = 32,\n",
    "    output_dir: Path = BASELINE_OUTPUT_DIR,\n",
    "    batch_size: int = 4,\n",
    "    target_sr: Optional[int] = None,\n",
    "):\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    model.set_generation_params(duration=duration)\n",
    "    for i in tqdm(range(0, num_samples, batch_size)):\n",
    "        samples_in_this_batch = min(batch_size, num_samples - i)\n",
    "        batch = model.generate_unconditional(num_samples=samples_in_this_batch)\n",
    "        wavs = batch.cpu()\n",
    "        for j, wav in enumerate(wavs):\n",
    "            audio_write(\n",
    "                output_dir / f\"sample_{i + j}\",\n",
    "                wav,\n",
    "                model.sample_rate,\n",
    "                strategy=\"loudness\",\n",
    "            )\n",
    "            _resample_and_overwrite(\n",
    "                output_dir / f\"sample_{i + j}.wav\",\n",
    "                target_sr=target_sr,\n",
    "            )\n",
    "\n",
    "\n",
    "def conditional_generate_wrapper(\n",
    "    model: MusicGen,\n",
    "    prompts: dict[str, str],\n",
    "    duration: int = 16,\n",
    "    output_dir: Path = BASELINE_OUTPUT_DIR,\n",
    "    batch_size: int = 4,\n",
    "    target_sr: Optional[int] = None,\n",
    ") -> dict[str, dict[str, str]]:\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    model.set_generation_params(duration=duration)\n",
    "    prompt_id_pairs = list(prompts.items())\n",
    "    res = {}\n",
    "    for i in tqdm(range(0, len(prompt_id_pairs), batch_size)):\n",
    "        samples_in_this_batch = min(batch_size, len(prompt_id_pairs) - i)\n",
    "        batch = prompt_id_pairs[i : i + samples_in_this_batch]\n",
    "        prompts = []\n",
    "        ids = []\n",
    "        for track_id, prompt in batch:\n",
    "            prompts.append(prompt)\n",
    "            ids.append(track_id)\n",
    "        batch = model.generate(prompts)\n",
    "        wavs = batch.cpu()\n",
    "        for j, (wav, track_id) in enumerate(zip(wavs, ids)):\n",
    "            audio_write(\n",
    "                output_dir / f\"{track_id}\",\n",
    "                wav,\n",
    "                model.sample_rate,\n",
    "                strategy=\"loudness\",\n",
    "                loudness_compressor=True,\n",
    "            )\n",
    "            _resample_and_overwrite(\n",
    "                output_dir / f\"{track_id}.wav\",\n",
    "                target_sr=target_sr,\n",
    "            )\n",
    "            res[track_id] = {\n",
    "                \"prompt\": prompts[j],\n",
    "                \"generated_audio_file\": str(output_dir / f\"{track_id}.wav\"),\n",
    "            }\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_0 happening with proba (a bit of clipping is okay): 0.0013281250139698386 maximum scale:  1.2280017137527466\n",
      "CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_1 happening with proba (a bit of clipping is okay): 0.0010410156100988388 maximum scale:  1.4098337888717651\n",
      "CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_2 happening with proba (a bit of clipping is okay): 0.009599609300494194 maximum scale:  1.4785785675048828\n",
      "CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_3 happening with proba (a bit of clipping is okay): 0.009087890386581421 maximum scale:  1.3560988903045654\n",
      " 12%|█▎        | 1/8 [00:15<01:48, 15.47s/it]CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_4 happening with proba (a bit of clipping is okay): 0.00034374999813735485 maximum scale:  2.0891764163970947\n",
      "CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_5 happening with proba (a bit of clipping is okay): 0.00022656249348074198 maximum scale:  1.234475016593933\n",
      "CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_6 happening with proba (a bit of clipping is okay): 0.005503906402736902 maximum scale:  1.7283036708831787\n",
      "CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_7 happening with proba (a bit of clipping is okay): 7.812500371073838e-06 maximum scale:  1.1459356546401978\n",
      " 25%|██▌       | 2/8 [00:25<01:11, 11.99s/it]CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_8 happening with proba (a bit of clipping is okay): 7.031249697320163e-05 maximum scale:  1.4725909233093262\n",
      "CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_9 happening with proba (a bit of clipping is okay): 8.203124889405444e-05 maximum scale:  1.1224406957626343\n",
      "CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_10 happening with proba (a bit of clipping is okay): 0.0015625000232830644 maximum scale:  1.3347386121749878\n",
      "CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_11 happening with proba (a bit of clipping is okay): 0.000994140631519258 maximum scale:  2.06583309173584\n",
      " 38%|███▊      | 3/8 [00:42<01:11, 14.28s/it]CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_12 happening with proba (a bit of clipping is okay): 4.492187508731149e-05 maximum scale:  1.3571029901504517\n",
      "CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_13 happening with proba (a bit of clipping is okay): 0.0016484374646097422 maximum scale:  1.6337372064590454\n",
      "CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_14 happening with proba (a bit of clipping is okay): 0.005794921889901161 maximum scale:  1.8035703897476196\n",
      "CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_15 happening with proba (a bit of clipping is okay): 0.0034511717967689037 maximum scale:  1.5036990642547607\n",
      " 50%|█████     | 4/8 [00:59<01:01, 15.43s/it]CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_16 happening with proba (a bit of clipping is okay): 0.009488280862569809 maximum scale:  2.447509765625\n",
      "CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_17 happening with proba (a bit of clipping is okay): 0.0001191406263387762 maximum scale:  1.4462225437164307\n",
      "CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_18 happening with proba (a bit of clipping is okay): 0.0025664062704890966 maximum scale:  1.7260260581970215\n",
      " 62%|██████▎   | 5/8 [01:16<00:48, 16.15s/it]CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_20 happening with proba (a bit of clipping is okay): 0.00021484374883584678 maximum scale:  1.3204997777938843\n",
      "CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_21 happening with proba (a bit of clipping is okay): 0.0005468750023283064 maximum scale:  1.8927531242370605\n",
      "CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_22 happening with proba (a bit of clipping is okay): 0.002240234287455678 maximum scale:  1.2710500955581665\n",
      "CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_23 happening with proba (a bit of clipping is okay): 5.859374869032763e-05 maximum scale:  1.1075551509857178\n",
      " 75%|███████▌  | 6/8 [01:32<00:31, 15.94s/it]CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_24 happening with proba (a bit of clipping is okay): 0.0003183593798894435 maximum scale:  1.1079562902450562\n",
      "CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_25 happening with proba (a bit of clipping is okay): 0.00016406249778810889 maximum scale:  1.2482072114944458\n",
      "CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_26 happening with proba (a bit of clipping is okay): 1.3671875422005542e-05 maximum scale:  1.2524042129516602\n",
      "CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_27 happening with proba (a bit of clipping is okay): 0.01884765550494194 maximum scale:  1.761518955230713\n",
      " 88%|████████▊ | 7/8 [01:41<00:13, 13.89s/it]CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_28 happening with proba (a bit of clipping is okay): 7.617187657160684e-05 maximum scale:  1.363682508468628\n",
      "CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_29 happening with proba (a bit of clipping is okay): 0.00281640631146729 maximum scale:  1.993567705154419\n",
      "CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_30 happening with proba (a bit of clipping is okay): 4.2968749767169356e-05 maximum scale:  1.1006031036376953\n",
      "CLIPPING /data/matt/mg_generated_audio/baseline/slakh_scaled_uncond/sample_31 happening with proba (a bit of clipping is okay): 0.00024023438163567334 maximum scale:  1.3296091556549072\n",
      "100%|██████████| 8/8 [01:51<00:00, 13.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/matt/mg_generated_audio/baseline/slakh_scaled_uncond\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# generate baseline\n",
    "output_dir = BASELINE_OUTPUT_DIR / \"slakh_scaled_uncond\"\n",
    "unconditional_generate_wrapper(\n",
    "    baseline,\n",
    "    duration=16,\n",
    "    num_samples=32,\n",
    "    output_dir=output_dir,\n",
    "    batch_size=4,\n",
    ")\n",
    "print(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_0 happening with proba (a bit of clipping is okay): 0.0013281250139698386 maximum scale:  1.789244532585144\n",
      "CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_1 happening with proba (a bit of clipping is okay): 0.00012109374802093953 maximum scale:  1.2391533851623535\n",
      "CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_2 happening with proba (a bit of clipping is okay): 0.006246093660593033 maximum scale:  1.9762834310531616\n",
      "CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_3 happening with proba (a bit of clipping is okay): 0.0003242187376599759 maximum scale:  1.3497477769851685\n",
      " 12%|█▎        | 1/8 [00:09<01:06,  9.56s/it]CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_4 happening with proba (a bit of clipping is okay): 0.002189453225582838 maximum scale:  1.5302330255508423\n",
      "CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_5 happening with proba (a bit of clipping is okay): 2.7343750844011083e-05 maximum scale:  1.0615031719207764\n",
      "CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_6 happening with proba (a bit of clipping is okay): 0.0004667968605645001 maximum scale:  1.3550838232040405\n",
      "CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_7 happening with proba (a bit of clipping is okay): 0.002550781238824129 maximum scale:  1.6705405712127686\n",
      " 25%|██▌       | 2/8 [00:19<00:57,  9.64s/it]CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_8 happening with proba (a bit of clipping is okay): 0.0015878906706348062 maximum scale:  1.6481432914733887\n",
      "CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_9 happening with proba (a bit of clipping is okay): 0.0010742187732830644 maximum scale:  1.4115978479385376\n",
      "CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_10 happening with proba (a bit of clipping is okay): 2.1484374883584678e-05 maximum scale:  1.1726890802383423\n",
      "CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_11 happening with proba (a bit of clipping is okay): 0.0001992187462747097 maximum scale:  1.4160423278808594\n",
      " 38%|███▊      | 3/8 [00:36<01:06, 13.24s/it]CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_12 happening with proba (a bit of clipping is okay): 0.0011191406520083547 maximum scale:  1.5276861190795898\n",
      "CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_13 happening with proba (a bit of clipping is okay): 0.0001425781229045242 maximum scale:  1.4481502771377563\n",
      "CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_14 happening with proba (a bit of clipping is okay): 0.00027929688803851604 maximum scale:  1.417217493057251\n",
      "CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_15 happening with proba (a bit of clipping is okay): 3.320312680443749e-05 maximum scale:  1.2169513702392578\n",
      " 50%|█████     | 4/8 [00:53<00:58, 14.66s/it]CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_16 happening with proba (a bit of clipping is okay): 0.00020703124755527824 maximum scale:  1.2334908246994019\n",
      "CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_17 happening with proba (a bit of clipping is okay): 0.00011328124674037099 maximum scale:  1.1429271697998047\n",
      "CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_18 happening with proba (a bit of clipping is okay): 0.0027792968321591616 maximum scale:  1.8186800479888916\n",
      "CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_19 happening with proba (a bit of clipping is okay): 4.492187508731149e-05 maximum scale:  1.105059266090393\n",
      " 62%|██████▎   | 5/8 [01:03<00:39, 13.04s/it]CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_20 happening with proba (a bit of clipping is okay): 4.101562444702722e-05 maximum scale:  1.1592328548431396\n",
      "CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_21 happening with proba (a bit of clipping is okay): 0.0011425780830904841 maximum scale:  2.2931296825408936\n",
      "CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_22 happening with proba (a bit of clipping is okay): 0.0006308594020083547 maximum scale:  1.4421119689941406\n",
      "CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_23 happening with proba (a bit of clipping is okay): 0.00991992186754942 maximum scale:  1.873957633972168\n",
      " 75%|███████▌  | 6/8 [01:13<00:23, 11.88s/it]CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_24 happening with proba (a bit of clipping is okay): 0.0032285156194120646 maximum scale:  1.9169337749481201\n",
      "CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_25 happening with proba (a bit of clipping is okay): 0.0017910156166180968 maximum scale:  1.5476444959640503\n",
      "CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_26 happening with proba (a bit of clipping is okay): 0.00011132812505820766 maximum scale:  1.314990520477295\n",
      "CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_27 happening with proba (a bit of clipping is okay): 0.0019628906156867743 maximum scale:  1.7026937007904053\n",
      " 88%|████████▊ | 7/8 [01:22<00:11, 11.12s/it]CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_28 happening with proba (a bit of clipping is okay): 0.0004023437504656613 maximum scale:  1.3476996421813965\n",
      "CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_29 happening with proba (a bit of clipping is okay): 0.00231054681353271 maximum scale:  1.70378577709198\n",
      "CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_30 happening with proba (a bit of clipping is okay): 9.570312249707058e-05 maximum scale:  1.293594479560852\n",
      "CLIPPING /data/matt/mg_generated_audio/finetune/slakh_scaled_uncond/sample_31 happening with proba (a bit of clipping is okay): 0.0010937500046566129 maximum scale:  1.6903010606765747\n",
      "100%|██████████| 8/8 [01:32<00:00, 11.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/matt/mg_generated_audio/finetune/slakh_scaled_uncond\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# generate unconditional\n",
    "output_dir = FINETUNE_OUTPUT_DIR / \"slakh_scaled_uncond\"\n",
    "unconditional_generate_wrapper(\n",
    "    ft_slakh,\n",
    "    duration=16,\n",
    "    num_samples=32,\n",
    "    output_dir=output_dir,\n",
    "    batch_size=4,\n",
    ")\n",
    "print(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example 2: text guided generation\n",
    "\n",
    "# wavs = musicgen.generate([\n",
    "#     'disco',\n",
    "#     'slide guitar bluegrass',\n",
    "#     'breakbeat, amen break',\n",
    "#     'epic orchestral strings'\n",
    "# ])\n",
    "\n",
    "# # save and display generated audio\n",
    "# for idx, one_wav in enumerate(wavs):\n",
    "#     audio_write(f'{idx}', one_wav.cpu(), musicgen.sample_rate, strategy=\"loudness\", loudness_compressor=True)\n",
    "#     ipd.display(ipd.Audio(one_wav.cpu(), rate=32000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcd_prompts = {track_id: v[\"prompt\"] for track_id, v in rcd.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_slakh = MusicGen.get_pretrained(slakh_scaled_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:52<00:00, 14.03s/it]\n"
     ]
    }
   ],
   "source": [
    "# conditional_generate_wrapper(\n",
    "#     ft_slakh,\n",
    "#     rcd_prompts,\n",
    "#     duration=16,\n",
    "#     output_dir=FINETUNE_OUTPUT_DIR / \"slakh_cond_v2\",\n",
    "#     batch_size=4,\n",
    "# )\n",
    "output_info = conditional_generate_wrapper(\n",
    "    ft_slakh,\n",
    "    rcd_prompts,\n",
    "    duration=16,\n",
    "    output_dir=FINETUNE_OUTPUT_DIR / \"slakh_scaled_cond\",\n",
    ")\n",
    "output_info_path = PROJECT_DATA_DIR / \"slakh/scaled_cond_output.json\"\n",
    "with open(output_info_path, \"w\") as f:\n",
    "    json.dump(output_info, f, indent=4)\n",
    "print(f\"Output info saved to {output_info_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:37<00:00, 12.23s/it]\n"
     ]
    }
   ],
   "source": [
    "output_info = conditional_generate_wrapper(\n",
    "    baseline,\n",
    "    rcd_prompts,\n",
    "    duration=16,\n",
    "    output_dir=BASELINE_OUTPUT_DIR / \"slakh_cond1\",\n",
    "    batch_size=4,\n",
    ")\n",
    "with open(PROJECT_DATA_DIR / \"slakh/baseline_cond1.json\", \"w\") as f:\n",
    "    json.dump(output_info, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_condition_data_with_output_audio_file_path(\n",
    "    condition_data: dict[str, dict[str, Any]],\n",
    "    output_dir: Path,\n",
    "):\n",
    "    res = {}\n",
    "    for track_id, info in condition_data.items():\n",
    "        target_path = output_dir / f\"{track_id}.wav\"\n",
    "        if not target_path.exists():\n",
    "            print(f\"Warning: {target_path} does not exist.\")\n",
    "            continue\n",
    "        res[track_id] = {\n",
    "            \"prompt\": info[\"prompt\"],\n",
    "            \"bpm\": info[\"bpm\"],\n",
    "            \"midi_program_names\": info[\"midi_program_names\"],\n",
    "            \"audio_file_path\": str(target_path),\n",
    "        }\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "clap_input_baseline = combine_condition_data_with_output_audio_file_path(\n",
    "    rcd,\n",
    "    BASELINE_OUTPUT_DIR / \"slakh_cond_v2\",\n",
    ")\n",
    "\n",
    "clap_input_finetune = combine_condition_data_with_output_audio_file_path(\n",
    "    rcd,\n",
    "    FINETUNE_OUTPUT_DIR / \"slakh_cond_v2\",\n",
    ")\n",
    "\n",
    "with open(PROJECT_DATA_DIR / \"clap_input_baseline.json\", \"w\") as f:\n",
    "    json.dump(clap_input_baseline, f, indent=4)\n",
    "\n",
    "with open(PROJECT_DATA_DIR / \"clap_input_finetune.json\", \"w\") as f:\n",
    "    json.dump(clap_input_finetune, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Caps Conditional Generation Experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_caps_wavs_dir = Path(\"/data/matt/music_caps/wavs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"google/MusicCaps\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0Gj8-vB1q4\n"
     ]
    }
   ],
   "source": [
    "dummy_id = dataset[0][\"ytid\"]\n",
    "print(dummy_id)\n",
    "file_path = music_caps_wavs_dir / f\"{dummy_id}.wav\"\n",
    "file_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220500,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, sr = librosa.load(file_path)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUSIC_CAPS_SR = 16000\n",
    "MUSIC_CAPS_DURATION = 10\n",
    "\n",
    "\n",
    "def prep_music_caps(\n",
    "    dataset: Dataset,\n",
    "    wav_dir: Path = music_caps_wavs_dir,\n",
    "    output_dir: Path = music_caps_wavs_dir.parent / \"audiocraft\",\n",
    "    train_split_size: int = 2048,\n",
    "    test_split_size: int = 32,\n",
    ") -> None:\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    dataset.shuffle(seed=42)  # Shuffle the dataset for randomness\n",
    "    train_dataset = dataset.select(range(train_split_size))\n",
    "    test_dataset = dataset.select(\n",
    "        range(train_split_size, train_split_size + test_split_size)\n",
    "    )\n",
    "    prep_music_caps_split(train_dataset, \"train\", wav_dir, output_dir)\n",
    "    prep_music_caps_split(test_dataset, \"test\", wav_dir, output_dir)\n",
    "\n",
    "\n",
    "def prep_music_caps_split(\n",
    "    dataset: Dataset,\n",
    "    split: str,\n",
    "    wav_dir: Path = music_caps_wavs_dir,\n",
    "    output_dir: Path = music_caps_wavs_dir.parent / \"audiocraft\",\n",
    ") -> None:\n",
    "    split_data = []\n",
    "    for entry in tqdm(dataset):\n",
    "        ytid = entry[\"ytid\"]\n",
    "        wav_path = wav_dir / f\"{ytid}.wav\"\n",
    "        if not wav_path.exists():\n",
    "            print(f\"Warning: {wav_path} does not exist.\")\n",
    "            continue\n",
    "\n",
    "        # use librosa to estimate key\n",
    "        y, sr = librosa.load(wav_path, sr=None)\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        key = np.argmax(np.sum(chroma, axis=1))\n",
    "\n",
    "        ac_entry = {\n",
    "            \"key\": str(key),\n",
    "            \"sample_rate\": MUSIC_CAPS_SR,\n",
    "            \"file_extension\": \"wav\",\n",
    "            \"description\": entry[\"caption\"],\n",
    "            \"keywords\": \"\",\n",
    "            \"duration\": MUSIC_CAPS_DURATION,\n",
    "            \"bpm\": \"\",\n",
    "            \"genre\": \"\",\n",
    "            \"title\": \"\",\n",
    "            \"name\": \"\",\n",
    "            \"instrument\": \"\",\n",
    "            \"moods\": [],\n",
    "            \"path\": str(wav_path),\n",
    "        }\n",
    "        split_data.append(ac_entry)\n",
    "    split_dir = output_dir / split\n",
    "    split_dir.mkdir(parents=True, exist_ok=True)\n",
    "    write_jsonl(split_data, output_dir / split / \"data.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 147/2048 [00:06<01:22, 23.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /data/matt/music_caps/wavs/0J_2K1Gvruk.wav does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 202/2048 [00:08<00:55, 33.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /data/matt/music_caps/wavs/0fqtA_ZBn_8.wav does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 397/2048 [00:17<01:08, 24.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /data/matt/music_caps/wavs/2dyxjGTXSpA.wav does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 724/2048 [00:31<00:51, 25.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /data/matt/music_caps/wavs/63rqIYPHvlc.wav does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 821/2048 [00:35<00:47, 26.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /data/matt/music_caps/wavs/7B1OAtD_VIA.wav does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 855/2048 [00:36<00:51, 23.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /data/matt/music_caps/wavs/7WZwlOrRELI.wav does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 1157/2048 [00:48<00:35, 25.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /data/matt/music_caps/wavs/Ah_aYOGnQ_I.wav does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 1210/2048 [00:50<00:33, 25.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /data/matt/music_caps/wavs/B7iRvj8y9aU.wav does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 1282/2048 [00:53<00:31, 24.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /data/matt/music_caps/wavs/BiQik0xsWxk.wav does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 1336/2048 [00:56<00:31, 22.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /data/matt/music_caps/wavs/C7OIuhWSbjU.wav does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 1745/2048 [01:12<00:14, 21.10it/s]/data/matt/miniconda3/envs/audiocraft/lib/python3.9/site-packages/librosa/core/pitch.py:103: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n",
      " 87%|████████▋ | 1783/2048 [01:14<00:09, 26.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /data/matt/music_caps/wavs/HAHn_zB47ig.wav does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1924/2048 [01:20<00:04, 25.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /data/matt/music_caps/wavs/IbJh1xeBFcI.wav does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [01:25<00:00, 23.92it/s]\n",
      "100%|██████████| 32/32 [00:01<00:00, 21.60it/s]\n"
     ]
    }
   ],
   "source": [
    "prep_music_caps(\n",
    "    dataset,\n",
    "    wav_dir=music_caps_wavs_dir,\n",
    "    output_dir=music_caps_wavs_dir.parent / \"audiocraft\",\n",
    "    train_split_size=2048,\n",
    "    test_split_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run training with dora framework\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_caps_train_command = \"\"\"\\\n",
    "TMPDIR=/data/matt/tmp CUDA_VISIBLE_DEVICES=4,5,6,7 dora -P audiocraft run \\\n",
    "  solver=musicgen/musicgen_base_32khz \\\n",
    "  +model.lm.model_scale=small \\\n",
    "  continue_from=//pretrained/facebook/musicgen-small \\\n",
    "  conditioner=text2music \\\n",
    "  dset=audio/music_caps \\\n",
    "  dataset.num_workers=4 \\\n",
    "  dataset.valid.num_samples=32 \\\n",
    "  dataset.batch_size=4 \\\n",
    "  schedule.cosine.warmup=8 \\\n",
    "  optim.optimizer=adamw \\\n",
    "  optim.lr=1e-4 \\\n",
    "  optim.epochs=3 \\\n",
    "  optim.updates_per_epoch=1000 \\\n",
    "  optim.adam.weight_decay=0.01 \\\n",
    "  generate.lm.prompted_samples=False \\\n",
    "  generate.lm.gen_gt_samples=True\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{music_caps_train_command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export checkpoint\n",
    "MC_V1_CKPT_DIR = CKPT_DIR / \"mc_v1\"\n",
    "MC_V1_SIG = \"40b4c24f\"\n",
    "export_model_checkpoint(MC_V1_SIG, ckpt_d=MC_V1_CKPT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate new samples from MusicCaps fine-tuned model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/audiocraft/audiocraft/models/musicgen.py:83: UserWarning: MusicGen pretrained model relying on deprecated checkpoint mapping. Please use full pre-trained id instead: facebook/musicgen-small\n",
      "  warnings.warn(\n",
      "/data/matt/miniconda3/envs/audiocraft/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(5)\n",
    "baseline_mc = MusicGen.get_pretrained(\"small\")\n",
    "mc_ckpt = MC_V1_CKPT_DIR\n",
    "ft_mc = MusicGen.get_pretrained(mc_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_music_cap_test_prompts():\n",
    "    music_cap_prompts = {}\n",
    "    mc_test_jsonl_path = music_caps_wavs_dir.parent / \"audiocraft/test/data.jsonl\"\n",
    "    lines = mc_test_jsonl_path.read_text().splitlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        entry = json.loads(line)\n",
    "        id_ = f\"mc_test{i}\"\n",
    "        music_cap_prompts[id_] = entry[\"description\"]\n",
    "    return music_cap_prompts\n",
    "\n",
    "\n",
    "music_cap_prompts = get_music_cap_test_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:14<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconditional_generate_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaseline_mc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmusic_cap_prompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMUSIC_CAPS_DURATION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBASELINE_OUTPUT_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmc_cond_v1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_sr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mMUSIC_CAPS_SR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[115], line 77\u001b[0m, in \u001b[0;36mconditional_generate_wrapper\u001b[0;34m(model, prompts, duration, output_dir, batch_size, target_sr)\u001b[0m\n\u001b[1;32m     65\u001b[0m         audio_write(\n\u001b[1;32m     66\u001b[0m             output_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrack_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     67\u001b[0m             wav,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m             loudness_compressor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     71\u001b[0m         )\n\u001b[1;32m     72\u001b[0m         _resample_and_overwrite(\n\u001b[1;32m     73\u001b[0m             output_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrack_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     74\u001b[0m             target_sr\u001b[38;5;241m=\u001b[39mtarget_sr,\n\u001b[1;32m     75\u001b[0m         )\n\u001b[1;32m     76\u001b[0m         res[track_id] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m---> 77\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mprompts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrack_id\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[1;32m     78\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_audio_file\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(output_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrack_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     79\u001b[0m         }\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "conditional_generate_wrapper(\n",
    "    model=baseline_mc,\n",
    "    prompts=music_cap_prompts,\n",
    "    duration=MUSIC_CAPS_DURATION,\n",
    "    output_dir=BASELINE_OUTPUT_DIR / \"mc_cond_v1\",\n",
    "    target_sr=MUSIC_CAPS_SR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## music genre dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 16/16 [01:41<00:00,  6.33s/files]\n",
      "Generating train split: 100%|██████████| 19909/19909 [00:39<00:00, 508.62 examples/s]\n",
      "Generating test split: 100%|██████████| 5076/5076 [00:09<00:00, 538.92 examples/s]\n"
     ]
    }
   ],
   "source": [
    "music_genre_dataset = load_dataset(\"lewtun/music_genres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mge0 = music_genre_dataset[\"train\"][0]\n",
    "isinstance(mge0[\"audio\"][\"array\"], np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': {'path': None,\n",
       "  'array': array([ 3.97140170e-07,  7.30310376e-07,  7.56406820e-07, ...,\n",
       "         -1.19636677e-01, -1.16811883e-01, -1.12441715e-01]),\n",
       "  'sampling_rate': 44100},\n",
       " 'song_id': 0,\n",
       " 'genre_id': 0,\n",
       " 'genre': 'Electronic'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mge0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENRE_AUDIO_FILES = PROJECT_DATA_DIR / \"music_genre_audio_files\"\n",
    "GENRE_AUDIO_FILES.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def prepare_genre_data(\n",
    "    dataset: Dataset,\n",
    "    output_dir: Path,\n",
    "    train_split_size: int = 2048,\n",
    "    test_split_size: int = 32,\n",
    "    target_sr: int = 32000,\n",
    ") -> None:\n",
    "    dataset = dataset.shuffle(seed=42)  # Shuffle the dataset for randomness\n",
    "    train_dataset = dataset.select(range(train_split_size))\n",
    "    test_dataset = dataset.select(\n",
    "        range(train_split_size, train_split_size + test_split_size)\n",
    "    )\n",
    "    prep_genre_split(train_dataset, \"train\", output_dir, target_sr)\n",
    "    prep_genre_split(test_dataset, \"test\", output_dir, target_sr)\n",
    "\n",
    "\n",
    "def prep_genre_split(\n",
    "    dataset: Dataset,\n",
    "    split: str,\n",
    "    output_dir: Path,\n",
    "    target_sr: int = 32000,\n",
    ") -> None:\n",
    "    split_data = []\n",
    "    for i, e in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "        # step 1: write out the audio (array) to a file\n",
    "        audio_array = e[\"audio\"][\"array\"]\n",
    "        sr = e[\"audio\"][\"sampling_rate\"]\n",
    "        audio_file_path = GENRE_AUDIO_FILES / f\"{i}.wav\"\n",
    "        resampled_audio = librosa.resample(audio_array, orig_sr=sr, target_sr=target_sr)\n",
    "        sf.write(\n",
    "            audio_file_path,\n",
    "            resampled_audio,\n",
    "            samplerate=sr,\n",
    "            format=\"WAV\",\n",
    "        )\n",
    "        # step 2: write out the metadata in the format expected by MusicGen\n",
    "        entry = {\n",
    "            \"key\": \"\",\n",
    "            \"sample_rate\": sr,\n",
    "            \"file_extension\": \"wav\",\n",
    "            \"description\": \"\",\n",
    "            \"keywords\": \"\",\n",
    "            \"duration\": 30,\n",
    "            \"bpm\": \"\",\n",
    "            \"genre\": e[\"genre\"],\n",
    "            \"title\": \"\",\n",
    "            \"name\": \"\",\n",
    "            \"instrument\": \"\",\n",
    "            \"moods\": [],\n",
    "            \"path\": str(audio_file_path),\n",
    "        }\n",
    "        split_data.append(entry)\n",
    "    split_dir = output_dir / split\n",
    "    split_dir.mkdir(parents=True, exist_ok=True)\n",
    "    write_jsonl(split_data, split_dir / \"data.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2048 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [05:47<00:00,  5.89it/s]\n",
      "100%|██████████| 32/32 [00:04<00:00,  6.78it/s]\n"
     ]
    }
   ],
   "source": [
    "ac_genre_dir = PROJECT_DATA_DIR / \"genre_audiocraft\"\n",
    "ac_genre_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "prepare_genre_data(\n",
    "    music_genre_dataset[\"train\"],\n",
    "    output_dir=ac_genre_dir,\n",
    "    train_split_size=2048,\n",
    "    test_split_size=32,\n",
    "    target_sr=32000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## music genre generation time please please please\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genre_prompts():\n",
    "    genre_prompts = {}\n",
    "    genre_jsonl_path = ac_genre_dir / \"test/data.jsonl\"\n",
    "    lines = genre_jsonl_path.read_text().splitlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        entry = json.loads(line)\n",
    "        id_ = f\"genre_test{i}\"\n",
    "        genre_prompts[id_] = entry[\"genre\"]\n",
    "    return genre_prompts\n",
    "\n",
    "\n",
    "genre_prompts = get_genre_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /tmp/audiocraft_matt/xps/49fd2443/checkpoint.th\n",
    "genre_sig = \"49fd2443\"\n",
    "genre_checkpoint_dir = CKPT_DIR / \"music_genre_v1e1\"\n",
    "export_model_checkpoint(\n",
    "    genre_sig,\n",
    "    ckpt_d=genre_checkpoint_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_v1e1 = MusicGen.get_pretrained(genre_checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'genre_test0': 'Pop',\n",
       " 'genre_test1': 'Rock',\n",
       " 'genre_test2': 'International',\n",
       " 'genre_test3': 'Hip-Hop',\n",
       " 'genre_test4': 'Experimental',\n",
       " 'genre_test5': 'Electronic',\n",
       " 'genre_test6': 'Punk',\n",
       " 'genre_test7': 'Hip-Hop',\n",
       " 'genre_test8': 'Chiptune / Glitch',\n",
       " 'genre_test9': 'Folk',\n",
       " 'genre_test10': 'Old-Time / Historic',\n",
       " 'genre_test11': 'Hip-Hop',\n",
       " 'genre_test12': 'Punk',\n",
       " 'genre_test13': 'Chiptune / Glitch',\n",
       " 'genre_test14': 'Rock',\n",
       " 'genre_test15': 'Punk',\n",
       " 'genre_test16': 'Pop',\n",
       " 'genre_test17': 'Electronic',\n",
       " 'genre_test18': 'Electronic',\n",
       " 'genre_test19': 'Rock',\n",
       " 'genre_test20': 'Instrumental',\n",
       " 'genre_test21': 'Jazz',\n",
       " 'genre_test22': 'Punk',\n",
       " 'genre_test23': 'Folk',\n",
       " 'genre_test24': 'Hip-Hop',\n",
       " 'genre_test25': 'Rock',\n",
       " 'genre_test26': 'Punk',\n",
       " 'genre_test27': 'Blues',\n",
       " 'genre_test28': 'Classical',\n",
       " 'genre_test29': 'Rock',\n",
       " 'genre_test30': 'Rock',\n",
       " 'genre_test31': 'Pop'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]CLIPPING /data/matt/mg_generated_audio/finetune/genre_uncond_v1e1/sample_1 happening with proba (a bit of clipping is okay): 1.0416666782475659e-06 maximum scale:  1.0830597877502441\n",
      "CLIPPING /data/matt/mg_generated_audio/finetune/genre_uncond_v1e1/sample_2 happening with proba (a bit of clipping is okay): 3.12499992105586e-06 maximum scale:  1.0476261377334595\n",
      "CLIPPING /data/matt/mg_generated_audio/finetune/genre_uncond_v1e1/sample_3 happening with proba (a bit of clipping is okay): 0.0004385416687000543 maximum scale:  1.5941087007522583\n",
      " 50%|█████     | 1/2 [00:20<00:20, 20.20s/it]CLIPPING /data/matt/mg_generated_audio/finetune/genre_uncond_v1e1/sample_5 happening with proba (a bit of clipping is okay): 0.0006447916384786367 maximum scale:  1.8232024908065796\n",
      "100%|██████████| 2/2 [00:37<00:00, 18.57s/it]\n"
     ]
    }
   ],
   "source": [
    "unconditional_generate_wrapper(\n",
    "    model=genre_v1e1,\n",
    "    duration=30,\n",
    "    num_samples=8,\n",
    "    output_dir=FINETUNE_OUTPUT_DIR / \"genre_uncond_v1e1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [02:59<00:00, 22.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre conditional outputs saved to /data/matt/mg_generated_audio/finetune/genre_uncond_v1e1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_dir = FINETUNE_OUTPUT_DIR / \"genre_cond_v1e1\"\n",
    "genre_cond_outputs = conditional_generate_wrapper(\n",
    "    model=genre_v1e1,\n",
    "    prompts=genre_prompts,\n",
    "    duration=30,\n",
    "    output_dir=output_dir,\n",
    ")\n",
    "print(f\"Genre conditional outputs saved to {output_dir}\")\n",
    "with open(PROJECT_DATA_DIR / \"genre_cond_v1e1_outputs.json\", \"w\") as f:\n",
    "    json.dump(genre_cond_outputs, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = FINETUNE_OUTPUT_DIR / \"genre_cond1\"\n",
    "genre_cond_outputs = conditional_generate_wrapper(\n",
    "    model=baseline,\n",
    "    prompts=genre_prompts,\n",
    "    duration=30,\n",
    "    output_dir=output_dir,\n",
    ")\n",
    "print(f\"Genre conditional outputs saved to {output_dir}\")\n",
    "with open(PROJECT_DATA_DIR / \"genre_cond_v1e1_outputs.json\", \"w\") as f:\n",
    "    json.dump(genre_cond_outputs, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/data/matt/pg_bpm.json\") as f:\n",
    "    bpm_info = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpm_info_fixed = {}\n",
    "for k, v in bpm_info.items():\n",
    "    k_fixed = k.replace(\"bespoke_data\", \"bespoke30\")\n",
    "    bpm_info_fixed[k_fixed] = v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/data/matt/bespoke30/piano_00.wav': 117,\n",
       " '/data/matt/bespoke30/piano_01.wav': 108,\n",
       " '/data/matt/bespoke30/piano_02.wav': 77,\n",
       " '/data/matt/bespoke30/piano_03.wav': 105,\n",
       " '/data/matt/bespoke30/piano_04.wav': 110,\n",
       " '/data/matt/bespoke30/piano_05.wav': 98,\n",
       " '/data/matt/bespoke30/piano_06.wav': 92,\n",
       " '/data/matt/bespoke30/piano_07.wav': 100,\n",
       " '/data/matt/bespoke30/piano_08.wav': 69,\n",
       " '/data/matt/bespoke30/piano_09.wav': 94,\n",
       " '/data/matt/bespoke30/piano_10.wav': 128,\n",
       " '/data/matt/bespoke30/piano_11.wav': 90,\n",
       " '/data/matt/bespoke30/piano_12.wav': 115,\n",
       " '/data/matt/bespoke30/piano_13.wav': 65,\n",
       " '/data/matt/bespoke30/piano_14.wav': 104,\n",
       " '/data/matt/bespoke30/piano_15.wav': 120,\n",
       " '/data/matt/bespoke30/piano_16.wav': 110,\n",
       " '/data/matt/bespoke30/piano_17.wav': 120,\n",
       " '/data/matt/bespoke30/piano_18.wav': 120,\n",
       " '/data/matt/bespoke30/piano_19.wav': 69,\n",
       " '/data/matt/bespoke30/guitar_00.wav': 120,\n",
       " '/data/matt/bespoke30/guitar_01.wav': 50,\n",
       " '/data/matt/bespoke30/guitar_02.wav': 80,\n",
       " '/data/matt/bespoke30/guitar_03.wav': 200,\n",
       " '/data/matt/bespoke30/guitar_04.wav': 70,\n",
       " '/data/matt/bespoke30/guitar_05.wav': 96,\n",
       " '/data/matt/bespoke30/guitar_06.wav': 117,\n",
       " '/data/matt/bespoke30/guitar_07.wav': 93,\n",
       " '/data/matt/bespoke30/guitar_08.wav': 108,\n",
       " '/data/matt/bespoke30/guitar_09.wav': 123,\n",
       " '/data/matt/bespoke30/guitar_10.wav': 103,\n",
       " '/data/matt/bespoke30/guitar_11.wav': 98,\n",
       " '/data/matt/bespoke30/guitar_12.wav': 75,\n",
       " '/data/matt/bespoke30/guitar_13.wav': 120,\n",
       " '/data/matt/bespoke30/guitar_14.wav': 135,\n",
       " '/data/matt/bespoke30/guitar_15.wav': 122,\n",
       " '/data/matt/bespoke30/guitar_16.wav': 96,\n",
       " '/data/matt/bespoke30/guitar_17.wav': 75,\n",
       " '/data/matt/bespoke30/guitar_18.wav': 129,\n",
       " '/data/matt/bespoke30/guitar_19.wav': 117}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpm_info_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_bespoke(\n",
    "    data_dir: Path,\n",
    "    output_dir: Path,\n",
    "    num_train_samples: int = 15,\n",
    "    num_test_samples: int = 5,\n",
    ") -> list[str]:\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    test_ids = []\n",
    "    train_inst_counts = defaultdict(lambda: 0)\n",
    "    for wav_file in os.listdir(data_dir):\n",
    "        if \"piano\" in wav_file:\n",
    "            inst = \"Piano\"\n",
    "            prefix = \"piano_\"\n",
    "        else:\n",
    "            assert \"guitar\" in wav_file\n",
    "            inst = \"Guitar\"\n",
    "            prefix = \"guitar_\"\n",
    "        id_ = wav_file.split(\".\")[0].replace(prefix, \"\")\n",
    "        path_ = str(data_dir / wav_file)\n",
    "        bpm = bpm_info_fixed.get(path_, \"\")\n",
    "\n",
    "        ac_entry = {\n",
    "            \"key\": \"\",\n",
    "            \"sample_rate\": SLAKH_SAMPLE_RATE,\n",
    "            \"file_extension\": \"wav\",\n",
    "            \"description\": inst,\n",
    "            \"keywords\": \"\",\n",
    "            \"duration\": 30,\n",
    "            \"bpm\": bpm,\n",
    "            \"genre\": \"\",\n",
    "            \"title\": \"\",\n",
    "            \"name\": \"\",\n",
    "            \"instrument\": inst,\n",
    "            \"moods\": [],\n",
    "            \"path\": str(data_dir / wav_file),\n",
    "        }\n",
    "        inst_count = train_inst_counts[inst]\n",
    "        if inst_count < num_train_samples:\n",
    "            train_inst_counts[inst] += 1\n",
    "            train_data.append(ac_entry)\n",
    "        else:\n",
    "            test_ids.append(f\"{inst}_{id_}.wav\")\n",
    "            test_data.append(ac_entry)\n",
    "\n",
    "    for split in (\"train\", \"test\"):\n",
    "        split_dir = output_dir / split\n",
    "        split_dir.mkdir(parents=True, exist_ok=True)\n",
    "        split_data = train_data if split == \"train\" else test_data\n",
    "        write_jsonl(split_data, output_dir / split / \"data.jsonl\")\n",
    "\n",
    "    return test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "BESPOKE_DIR = Path(\"/data/matt/bespoke30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Guitar_04.wav',\n",
       " 'Guitar_15.wav',\n",
       " 'Piano_19.wav',\n",
       " 'Piano_14.wav',\n",
       " 'Piano_12.wav',\n",
       " 'Piano_15.wav',\n",
       " 'Piano_04.wav',\n",
       " 'Guitar_14.wav',\n",
       " 'Guitar_06.wav',\n",
       " 'Guitar_18.wav']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_bespoke(\n",
    "    data_dir=BESPOKE_DIR,\n",
    "    output_dir=PROJECT_DATA_DIR / \"audiocraft_bespoke30bpm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [06-03 10:13:47][audiocraft.utils.checkpoint][INFO] - Checkpoint saved to /tmp/audiocraft_matt/xps/d7ebad35/checkpoint.th\n",
    "# b_sig = \"d7ebad35\"\n",
    "# b_checkpoint_dir = CKPT_DIR / \"bespoke30_v1\"\n",
    "# export_model_checkpoint(\n",
    "#     b_sig,\n",
    "#     ckpt_d=b_checkpoint_dir,\n",
    "# )\n",
    "\n",
    "# [06-03 11:09:42][audiocraft.utils.checkpoint][INFO] - Checkpoint saved to /tmp/audiocraft_matt/xps/d703f0e0/checkpoint.th\n",
    "b_sig = \"d703f0e0\"\n",
    "b_checkpoint_dir = CKPT_DIR / \"bespoke30_bpm\"\n",
    "export_model_checkpoint(\n",
    "    b_sig,\n",
    "    ckpt_d=b_checkpoint_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_test_set = [\n",
    "    \"Guitar_04.wav\",\n",
    "    \"Guitar_15.wav\",\n",
    "    \"Piano_19.wav\",\n",
    "    \"Piano_14.wav\",\n",
    "    \"Piano_12.wav\",\n",
    "    \"Piano_15.wav\",\n",
    "    \"Piano_04.wav\",\n",
    "    \"Guitar_14.wav\",\n",
    "    \"Guitar_06.wav\",\n",
    "    \"Guitar_18.wav\",\n",
    "]\n",
    "pg_prompts = {}\n",
    "pg_ref_dir = PROJECT_DATA_DIR / \"pg_test_ref\"\n",
    "pg_ref_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "for wav_file in pg_test_set:\n",
    "    wav_file_p = BESPOKE_DIR / wav_file.lower()\n",
    "    shutil.copy(wav_file_p, pg_ref_dir / wav_file.lower())\n",
    "    wav_file_s = str(wav_file_p)\n",
    "    bpm = bpm_info_fixed.get(wav_file_s, \"\")\n",
    "    pg_prompts[wav_file.lower().replace(\".wav\", \"\")] = (\n",
    "        f\"{bpm} BPM with {wav_file.split('_')[0]}.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# pg_prompts = {}\n",
    "# for i in range(5):\n",
    "#     pg_prompts[f\"piano_{i}\"] = \"Piano\"\n",
    "#     pg_prompts[f\"guitar_{i}\"] = \"Guitar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guitar_04': '70 BPM with Guitar.',\n",
       " 'guitar_15': '122 BPM with Guitar.',\n",
       " 'piano_19': '69 BPM with Piano.',\n",
       " 'piano_14': '104 BPM with Piano.',\n",
       " 'piano_12': '115 BPM with Piano.',\n",
       " 'piano_15': '120 BPM with Piano.',\n",
       " 'piano_04': '110 BPM with Piano.',\n",
       " 'guitar_14': '135 BPM with Guitar.',\n",
       " 'guitar_06': '117 BPM with Guitar.',\n",
       " 'guitar_18': '129 BPM with Guitar.'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_model = MusicGen.get_pretrained(b_checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:34<00:00, 11.61s/it]\n"
     ]
    }
   ],
   "source": [
    "b_model_cond_out = conditional_generate_wrapper(\n",
    "    model=b_model,\n",
    "    prompts=pg_prompts,\n",
    "    duration=10,\n",
    "    output_dir=FINETUNE_OUTPUT_DIR / \"bespoke_cond_bpm\",\n",
    ")\n",
    "\n",
    "with open(PROJECT_DATA_DIR / \"bespoke_ft_cond_bpm_outputs.json\", \"w\") as f:\n",
    "    json.dump(b_model_cond_out, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/matt/cse253a2/bespoke_ft_cond_v1_outputs.json\n"
     ]
    }
   ],
   "source": [
    "print(PROJECT_DATA_DIR / \"bespoke_ft_cond_v1_outputs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:34<00:00, 11.37s/it]\n"
     ]
    }
   ],
   "source": [
    "pg_ft_out = conditional_generate_wrapper(\n",
    "    model=baseline,\n",
    "    prompts=pg_prompts,\n",
    "    duration=10,\n",
    "    output_dir=BASELINE_OUTPUT_DIR / \"bespoke_cond_bpm\",\n",
    ")\n",
    "\n",
    "with open(PROJECT_DATA_DIR / \"bespoke_cond_bpm_outputs.json\", \"w\") as f:\n",
    "    json.dump(pg_ft_out, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guitar_04': '70 BPM with Guitar.',\n",
       " 'guitar_15': '122 BPM with Guitar.',\n",
       " 'piano_19': '69 BPM with Piano.',\n",
       " 'piano_14': '104 BPM with Piano.',\n",
       " 'piano_12': '115 BPM with Piano.',\n",
       " 'piano_15': '120 BPM with Piano.',\n",
       " 'piano_04': '110 BPM with Piano.',\n",
       " 'guitar_14': '135 BPM with Guitar.',\n",
       " 'guitar_06': '117 BPM with Guitar.',\n",
       " 'guitar_18': '129 BPM with Guitar.'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/matt/cse253a2/bespoke_cond_v1_outputs.json\n"
     ]
    }
   ],
   "source": [
    "print(PROJECT_DATA_DIR / \"bespoke_cond_v1_outputs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audiocraft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
