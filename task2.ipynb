{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Unconditioned Symbolic Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/matt/miniconda3/envs/audiocraft/lib/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matt/audiocraft\n",
      "\u001b[2mUsing Python 3.9.21 environment at: /data/matt/miniconda3/envs/audiocraft\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m152 packages\u001b[0m \u001b[2min 1.03s\u001b[0m\u001b[0m                                       \u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m     0 B/5.38 KiB                      \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 7ms\u001b[0m\u001b[0m                                                    \u001b[1A\n",
      "\u001b[2mUninstalled \u001b[1m15 packages\u001b[0m \u001b[2min 250ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m107 packages\u001b[0m \u001b[2min 453ms\u001b[0m\u001b[0m                             \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiofiles\u001b[0m\u001b[2m==23.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maudiocraft\u001b[0m\u001b[2m==1.4.0a2 (from file:///home/matt/audiocraft)\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mav\u001b[0m\u001b[2m==11.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mblis\u001b[0m\u001b[2m==0.7.11\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcatalogue\u001b[0m\u001b[2m==2.0.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.1.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcloudpathlib\u001b[0m\u001b[2m==0.21.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcolorlog\u001b[0m\u001b[2m==6.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mconfection\u001b[0m\u001b[2m==0.1.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcontourpy\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcycler\u001b[0m\u001b[2m==0.12.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcymem\u001b[0m\u001b[2m==2.0.11\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdemucs\u001b[0m\u001b[2m==4.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdocopt\u001b[0m\u001b[2m==0.6.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1meinops\u001b[0m\u001b[2m==0.8.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mencodec\u001b[0m\u001b[2m==0.1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfastapi\u001b[0m\u001b[2m==0.115.12\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mffmpy\u001b[0m\u001b[2m==0.6.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mflashy\u001b[0m\u001b[2m==0.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfonttools\u001b[0m\u001b[2m==4.58.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgradio\u001b[0m\u001b[2m==4.44.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgradio-client\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mh11\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhf-xet\u001b[0m\u001b[2m==1.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpcore\u001b[0m\u001b[2m==1.0.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpx\u001b[0m\u001b[2m==0.28.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.32.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhydra-colorlog\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhydra-core\u001b[0m\u001b[2m==1.3.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mimportlib-resources\u001b[0m\u001b[2m==6.5.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjulius\u001b[0m\u001b[2m==0.2.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mkiwisolver\u001b[0m\u001b[2m==1.4.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlameenc\u001b[0m\u001b[2m==1.8.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangcodes\u001b[0m\u001b[2m==3.5.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlanguage-data\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlightning-utilities\u001b[0m\u001b[2m==0.14.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarisa-trie\u001b[0m\u001b[2m==1.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkdown-it-py\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==2.1.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmatplotlib\u001b[0m\u001b[2m==3.9.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmdurl\u001b[0m\u001b[2m==0.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmurmurhash\u001b[0m\u001b[2m==1.0.13\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnum2words\u001b[0m\u001b[2m==0.5.14\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.6.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.1.3.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.6.80\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.1.105\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.1.105\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.1.105\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.5.1.17\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==8.9.2.26\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.0.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.0.2.54\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.7.77\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.2.106\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.4.5.107\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.4.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.1.0.106\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.26.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.18.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.1.105\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopenunmix\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1morjson\u001b[0m\u001b[2m==3.10.18\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.2.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpesq\u001b[0m\u001b[2m==0.0.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==10.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpreshed\u001b[0m\u001b[2m==3.0.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==6.31.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.11.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.33.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydub\u001b[0m\u001b[2m==0.25.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyparsing\u001b[0m\u001b[2m==3.2.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpystoi\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-multipart\u001b[0m\u001b[2m==0.0.20\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpytz\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mregex\u001b[0m\u001b[2m==2024.11.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrich\u001b[0m\u001b[2m==14.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mruff\u001b[0m\u001b[2m==0.11.12\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msafetensors\u001b[0m\u001b[2m==0.5.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msemantic-version\u001b[0m\u001b[2m==2.10.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msentencepiece\u001b[0m\u001b[2m==0.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mshellingham\u001b[0m\u001b[2m==1.5.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msmart-open\u001b[0m\u001b[2m==7.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msniffio\u001b[0m\u001b[2m==1.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mspacy\u001b[0m\u001b[2m==3.7.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mspacy-legacy\u001b[0m\u001b[2m==3.0.12\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mspacy-loggers\u001b[0m\u001b[2m==1.0.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msrsly\u001b[0m\u001b[2m==2.5.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mstarlette\u001b[0m\u001b[2m==0.46.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mthinc\u001b[0m\u001b[2m==8.2.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.21.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtomlkit\u001b[0m\u001b[2m==0.12.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorchaudio\u001b[0m\u001b[2m==2.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorchdata\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorchdiffeq\u001b[0m\u001b[2m==0.2.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorchmetrics\u001b[0m\u001b[2m==1.7.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorchtext\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.52.4\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==2.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyper\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-inspection\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtzdata\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1muvicorn\u001b[0m\u001b[2m==0.34.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwasabi\u001b[0m\u001b[2m==1.1.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mweasel\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwebsockets\u001b[0m\u001b[2m==12.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwrapt\u001b[0m\u001b[2m==1.17.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mxformers\u001b[0m\u001b[2m==0.0.22.post7\u001b[0m\n",
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`spacy==3.7.6` is yanked (reason: \"Incorrect compatibility for transformer models\")\u001b[0m\n",
      "\u001b[2mUsing Python 3.9.21 environment at: /data/matt/miniconda3/envs/audiocraft\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m5 packages\u001b[0m \u001b[2min 8ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/facebookresearch/audiocraft.git\n",
    "# %cd udiocraft\n",
    "# !uv pip install -e .\n",
    "# !uv pip install dora-search numba librosa mido PyYAML datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matt/audiocraft\n"
     ]
    }
   ],
   "source": [
    "%cd /home/matt/audiocraft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "import librosa\n",
    "import mido\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import yaml\n",
    "from datasets import Dataset, load_dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/matt/miniconda3/envs/audiocraft/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/data/matt/miniconda3/envs/audiocraft/lib/python3.9/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from audiocraft import train\n",
    "from audiocraft.data.audio import audio_write\n",
    "from audiocraft.models import MusicGen\n",
    "from audiocraft.utils import export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TMPDIR\"] = \"/data/matt/tmp\"\n",
    "PROJECT_DATA_DIR = Path(\"/data/matt/cse253a2\")\n",
    "PROJECT_DATA_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## slakh dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLAKH_DIR = Path(\"/data/matt/slakh2100_flac_redux\")\n",
    "BABYSLAKH_DIR = Path(\"/data/matt/babyslakh_16k\")\n",
    "TRACK_ID_PATTERN = re.compile(r\"slakh2100_flac_redux\\/(.+?)\\/Track(\\d+)\\/mix\\.flac$\")\n",
    "BABYSLAKH_TRACK_ID_PATTERN = re.compile(r\"\\/Track(\\d+)\\/mix\\.wav$\")\n",
    "DEFAULT_INSTRUMENTS = [\"Piano\", \"Bass\", \"Guitar\", \"Drums\"]\n",
    "DEFAULT_MIDI_TEMPO = 500000\n",
    "BABYSLAKH_SAMPLE_RATE = 16000\n",
    "SLAKH_SAMPLE_RATE = 44100\n",
    "\n",
    "\n",
    "def get_babyslakh_paths(root_dir: Path = BABYSLAKH_DIR) -> List[Path]:\n",
    "    return [\n",
    "        root_dir / track_dir / \"mix.wav\"\n",
    "        for track_dir in os.listdir(root_dir)\n",
    "        if \"Track\" in track_dir and (root_dir / track_dir / \"mix.wav\").exists()\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_slakh_paths(root_dir: Path = SLAKH_DIR) -> List[Path]:\n",
    "    splits = [\"train\", \"test\", \"validation\"]\n",
    "    paths = []\n",
    "    for split_dir in os.listdir(root_dir):\n",
    "        if split_dir not in splits:\n",
    "            continue\n",
    "        split_path = root_dir / split_dir\n",
    "        for track_dir in os.listdir(split_path):\n",
    "            mix_path = split_path / track_dir / \"mix.flac\"\n",
    "            if \"Track\" in track_dir and mix_path.exists():\n",
    "                paths.append(mix_path)\n",
    "    return paths\n",
    "\n",
    "\n",
    "def extract_sample_id(path: str, is_babyslakh: bool = False) -> Tuple[str, str]:\n",
    "    pattern = BABYSLAKH_TRACK_ID_PATTERN if is_babyslakh else TRACK_ID_PATTERN\n",
    "    match = pattern.search(path)\n",
    "    if match is None:\n",
    "        raise ValueError(f\"Track ID not found in path: {path}\")\n",
    "    if is_babyslakh:\n",
    "        coin_flip = random.randint(0, 1)\n",
    "        split = \"test\" if coin_flip == 0 else \"train\"\n",
    "        return split, match.group(1)\n",
    "    return match.group(1), match.group(2)\n",
    "\n",
    "\n",
    "def get_midi_program_names(track_directory: Path) -> List[str]:\n",
    "    try:\n",
    "        with open(track_directory / \"metadata.yaml\", \"r\") as f:\n",
    "            metadata = yaml.safe_load(f)\n",
    "        program_names = []\n",
    "        for stem_id, stem_info in metadata[\"stems\"].items():\n",
    "            if \"midi_program_name\" in stem_info:\n",
    "                program_names.append(stem_info[\"midi_program_name\"])\n",
    "        return program_names\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load metadata for {track_directory}: {e}\")\n",
    "        return DEFAULT_INSTRUMENTS\n",
    "\n",
    "\n",
    "def get_tempo(mid):\n",
    "    for track in mid.tracks:\n",
    "        for msg in track:\n",
    "            if msg.type == \"set_tempo\":\n",
    "                return msg.tempo\n",
    "    return DEFAULT_MIDI_TEMPO\n",
    "\n",
    "\n",
    "def get_bpm(track_directory: Path) -> int:\n",
    "    try:\n",
    "        mid = mido.MidiFile(track_directory / \"all_src.mid\")\n",
    "        tempo = get_tempo(mid)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to get tempo for {track_directory}: {e}\")\n",
    "        tempo = DEFAULT_MIDI_TEMPO\n",
    "    return round(mido.tempo2bpm(tempo))\n",
    "\n",
    "\n",
    "def get_condition_data(slakh_paths, is_babyslakh: bool = False) -> Dict[str, Any]:\n",
    "    condition_data = defaultdict(dict)\n",
    "    for audio_path in tqdm(slakh_paths):\n",
    "        track_directory = audio_path.parent\n",
    "        path_str = str(audio_path)\n",
    "        split, track_id = extract_sample_id(path_str, is_babyslakh=is_babyslakh)\n",
    "        if split == \"train\":\n",
    "            split = \"training\"\n",
    "        try:\n",
    "            bpm = get_bpm(track_directory)\n",
    "            program_names = get_midi_program_names(track_directory)\n",
    "            condition_data[split][track_id] = {\n",
    "                \"bpm\": bpm,\n",
    "                \"midi_program_names\": program_names,\n",
    "                \"track_path\": str(audio_path),\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Failed on {audio_path}: {e}\")\n",
    "    return condition_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1710 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1710/1710 [04:49<00:00,  5.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# babyslakh_paths = get_babyslakh_paths()\n",
    "# condition_data = get_condition_data(babyslakh_paths, is_babyslakh=True)\n",
    "slakh_paths = get_slakh_paths()\n",
    "condition_data = get_condition_data(slakh_paths, is_babyslakh=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/data/matt/all_conditions.json\", \"w\") as f:\n",
    "    json.dump(condition_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create .jsonl from the extracted features, make a train/test split, and save in the right place.\n",
    "\n",
    "\n",
    "def write_jsonl(data: list[dict], file_path: Path) -> None:\n",
    "    with open(file_path, \"w\") as f:\n",
    "        for entry in data:\n",
    "            f.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "\n",
    "def prepare_slakh_data(\n",
    "    split_directories: dict[str, Path],\n",
    "    sr: int = SLAKH_SAMPLE_RATE,\n",
    "    file_extension: str = \"flac\",\n",
    "):\n",
    "    for directory in split_directories.values():\n",
    "        directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    data_lists = {\n",
    "        \"train\": [],\n",
    "        \"test\": [],\n",
    "        \"validation\": [],\n",
    "    }\n",
    "\n",
    "    for split, split_data in condition_data.items():\n",
    "        if split == \"training\":\n",
    "            split = \"train\"\n",
    "        for track_id, track_info in tqdm(split_data.items(), total=len(split_data)):\n",
    "            path = Path(track_info[\"track_path\"])\n",
    "            y, sr = librosa.load(path)\n",
    "            chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "            key = np.argmax(np.sum(chroma, axis=1))\n",
    "            length = librosa.get_duration(y=y, sr=sr)\n",
    "            entry = {\n",
    "                \"key\": str(key),\n",
    "                \"sample_rate\": sr,\n",
    "                \"file_extension\": file_extension,\n",
    "                \"description\": \"\",\n",
    "                \"keywords\": \"\",\n",
    "                \"duration\": length,\n",
    "                \"bpm\": track_info[\"bpm\"],\n",
    "                \"genre\": \"\",\n",
    "                \"title\": \"\",\n",
    "                \"name\": \"\",\n",
    "                \"instrument\": \", \".join(track_info[\"midi_program_names\"]),\n",
    "                \"moods\": [],\n",
    "                \"path\": str(path),\n",
    "            }\n",
    "            data_lists[split].append(entry)\n",
    "\n",
    "    # print split sizes\n",
    "    for split, data in data_lists.items():\n",
    "        print(f\"{split} size: {len(data)}\")\n",
    "        write_jsonl(data, split_directories[split] / \"data.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1289/1289 [23:11<00:00,  1.08s/it]\n",
      "100%|██████████| 270/270 [04:49<00:00,  1.07s/it]\n",
      "100%|██████████| 151/151 [02:51<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 1289\n",
      "test size: 151\n",
      "validation size: 270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "music_gen_slakh_directory = Path(\"/data/matt/music_gen_slakh\")\n",
    "split_directories = {\n",
    "    \"train\": music_gen_slakh_directory / \"train\",\n",
    "    \"test\": music_gen_slakh_directory / \"test\",\n",
    "    \"validation\": music_gen_slakh_directory / \"validation\",\n",
    "}\n",
    "prepare_slakh_data(\n",
    "    split_directories,\n",
    "    sr=SLAKH_SAMPLE_RATE,\n",
    "    file_extension=\"flac\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run training with dora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train', 'validation', 'test']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(music_gen_slakh_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_command = \"\"\"\\\n",
    "CUDA_VISIBLE_DEVICES=4,5,6,7 dora -P audiocraft run \\\n",
    "  solver=musicgen/musicgen_base_32khz \\\n",
    "  +model.lm.model_scale=small \\\n",
    "  continue_from=//pretrained/facebook/musicgen-small \\\n",
    "  conditioner=text2music \\\n",
    "  dset=audio/babyslakh \\\n",
    "  dataset.num_workers=2 \\\n",
    "  dataset.valid.num_samples=1 \\\n",
    "  dataset.batch_size=2 \\\n",
    "  schedule.cosine.warmup=8 \\\n",
    "  optim.optimizer=adamw \\\n",
    "  optim.lr=1e-4 \\\n",
    "  optim.epochs=2 \\\n",
    "  optim.updates_per_epoch=100 \\\n",
    "  optim.adam.weight_decay=0.01 \\\n",
    "  generate.lm.prompted_samples=False \\\n",
    "  generate.lm.gen_gt_samples=True\n",
    "\"\"\"\n",
    "\n",
    "command = \"\"\"\\\n",
    "CUDA_VISIBLE_DEVICES=4,5,6,7 dora -P audiocraft run \\\n",
    "  solver=musicgen/musicgen_base_32khz \\\n",
    "  +model.lm.model_scale=small \\\n",
    "  continue_from=//pretrained/facebook/musicgen-small \\\n",
    "  conditioner=text2music \\\n",
    "  dset=audio/slakh \\\n",
    "  dataset.num_workers=4 \\\n",
    "  dataset.valid.num_samples=32 \\\n",
    "  dataset.batch_size=4 \\\n",
    "  schedule.cosine.warmup=8 \\\n",
    "  optim.optimizer=adamw \\\n",
    "  optim.lr=1e-4 \\\n",
    "  optim.epochs=1 \\\n",
    "  optim.updates_per_epoch=1000 \\\n",
    "  optim.adam.weight_decay=0.01 \\\n",
    "  generate.lm.prompted_samples=False \\\n",
    "  generate.lm.gen_gt_samples=True\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "Dora directory: /tmp/audiocraft_matt\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/matt/miniconda3/envs/cse253/bin/dora\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/dora/__main__.py\", line 170, in main\n",
      "    args.action(args, main)\n",
      "  File \"/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/dora/run.py\", line 51, in run_action\n",
      "    xp = main.get_xp(args.argv)\n",
      "  File \"/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/dora/hydra.py\", line 190, in get_xp\n",
      "    delta += self._get_delta(base, cfg)\n",
      "  File \"/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/dora/hydra.py\", line 297, in _get_delta\n",
      "    for diff in _compare_config(init, other):\n",
      "  File \"/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/dora/hydra.py\", line 75, in _compare_config\n",
      "    yield from _compare_config(ref_value, other_value, path)\n",
      "  File \"/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/dora/hydra.py\", line 67, in _compare_config\n",
      "    ref_value = ref[key]\n",
      "  File \"/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/omegaconf/dictconfig.py\", line 375, in __getitem__\n",
      "    self._format_and_raise(key=key, value=None, cause=e)\n",
      "  File \"/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/omegaconf/base.py\", line 231, in _format_and_raise\n",
      "    format_and_raise(\n",
      "  File \"/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/omegaconf/_utils.py\", line 899, in format_and_raise\n",
      "    _raise(ex, cause)\n",
      "  File \"/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/omegaconf/_utils.py\", line 797, in _raise\n",
      "    raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace\n",
      "  File \"/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/omegaconf/dictconfig.py\", line 369, in __getitem__\n",
      "    return self._get_impl(key=key, default_value=_DEFAULT_MARKER_)\n",
      "  File \"/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/omegaconf/dictconfig.py\", line 451, in _get_impl\n",
      "    return self._resolve_with_default(\n",
      "  File \"/data/matt/miniconda3/envs/cse253/lib/python3.9/site-packages/omegaconf/basecontainer.py\", line 96, in _resolve_with_default\n",
      "    raise MissingMandatoryValue(\"Missing mandatory value: $FULL_KEY\")\n",
      "omegaconf.errors.MissingMandatoryValue: Missing mandatory value: dataset.batch_size\n",
      "    full_key: dataset.batch_size\n",
      "    object_type=dict\n",
      "/bin/bash: line 2: model/lm/model_scale=small: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original (tmp has since been set to /data/matt/tmp)\n",
    "# samples_dir = Path(\"/tmp/audiocraft_matt/xps/ed9b1b62/samples\")\n",
    "# baby training run\n",
    "# sig = \"ed9b1b62\"\n",
    "sig = \"12c4508d\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export fine-tuned model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_dir = Path(\"/data/matt/mg_checkpoints\")\n",
    "v1_checkpoints_dir = checkpoints_dir / \"v1/finetune\"\n",
    "v2_checkpoints_dir = checkpoints_dir / \"v2/finetune\"\n",
    "checkpoints_dir = v2_checkpoints_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dora directory: /tmp/audiocraft_matt\n"
     ]
    }
   ],
   "source": [
    "# Exporting .bin files from a training run:\n",
    "\n",
    "\n",
    "sig = \"ed9b1b62\"\n",
    "\n",
    "# from https://github.com/facebookresearch/audiocraft/blob/main/docs/MUSICGEN.md#importing--exporting-models\n",
    "xp = train.main.get_xp_from_sig(sig)\n",
    "checkpoints_dir.mkdir(parents=True, exist_ok=True)\n",
    "export.export_lm(xp.folder / \"checkpoint.th\", checkpoints_dir / \"state_dict.bin\")\n",
    "export.export_pretrained_compression_model(\n",
    "    \"facebook/encodec_32khz\", checkpoints_dir / \"compression_state_dict.bin\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_DIR = Path(\"/data/matt/mg_checkpoints\")\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def export_model_checkpoint(sig: str, ckpt_d: Path = CKPT_DIR):\n",
    "    ckpt_d.mkdir(parents=True, exist_ok=True)\n",
    "    xp = train.main.get_xp_from_sig(sig)\n",
    "    export.export_lm(xp.folder / \"checkpoint.th\", ckpt_d / \"state_dict.bin\")\n",
    "    export.export_pretrained_compression_model(\n",
    "        \"facebook/encodec_32khz\",\n",
    "        ckpt_d / \"compression_state_dict.bin\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up reference directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create slakh test split reference (st_ref)\n",
    "slakh_test_dir = SLAKH_DIR / \"test\"\n",
    "slakh_reference_dir = Path(\"/data/matt/st_ref\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_slakh_reference_dir(\n",
    "    reference_dir: Path,\n",
    "    num_tracks: int = 32,\n",
    "    track_length: int = 16,\n",
    ") -> list[str]:\n",
    "    reference_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tracks_copied = 0\n",
    "    track_ids = []\n",
    "    for track_dir in os.listdir(slakh_test_dir):\n",
    "        if \"Track\" not in track_dir:\n",
    "            continue\n",
    "        mix_flac = slakh_test_dir / track_dir / \"mix.flac\"\n",
    "        if not mix_flac.exists():\n",
    "            continue\n",
    "        audio, original_sr = librosa.load(mix_flac, sr=None, mono=False)\n",
    "        resampled = librosa.resample(audio, orig_sr=original_sr, target_sr=32000)\n",
    "        # cut it down to the first `track_length` seconds\n",
    "        if resampled.ndim == 1:\n",
    "            resampled = resampled[: track_length * 32000]\n",
    "        elif resampled.ndim == 2:\n",
    "            resampled = resampled[:, : track_length * 32000]\n",
    "            # librosa returns (channels, samples), sf expects (samples, channels)\n",
    "            resampled = resampled.T\n",
    "        _, track_id = extract_sample_id(str(mix_flac))\n",
    "        destination = reference_dir / f\"track{track_id}.wav\"\n",
    "        sf.write(destination, resampled, samplerate=32000)\n",
    "        tracks_copied += 1\n",
    "        track_ids.append(str(track_id))\n",
    "        if tracks_copied >= num_tracks:\n",
    "            break\n",
    "    return track_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_track_ids = create_slakh_reference_dir(slakh_reference_dir, num_tracks=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1710/1710 [04:50<00:00,  5.88it/s]\n"
     ]
    }
   ],
   "source": [
    "condition_data = get_condition_data(\n",
    "    get_slakh_paths(SLAKH_DIR),\n",
    "    is_babyslakh=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PROJECT_DATA_DIR / \"original_metadata.json\", \"w\") as f:\n",
    "    json.dump(condition_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(bpm: int, midi_program_names: list[str]) -> str:\n",
    "    instruments = \", \".join(midi_program_names)\n",
    "    return f\"{bpm} BPM with {instruments}.\"\n",
    "\n",
    "\n",
    "def create_reference_condition_data(\n",
    "    condition_data: dict[str, Any],\n",
    "    reference_dir: Path,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Create a dictionary with reference condition data.\"\"\"\n",
    "    reference_condition_data = {}\n",
    "    for track_id, info in condition_data[\"test\"].items():\n",
    "        file_path = reference_dir / f\"track{track_id}.wav\"\n",
    "        if not file_path.exists():\n",
    "            continue\n",
    "        reference_condition_data[track_id] = {\n",
    "            \"bpm\": info[\"bpm\"],\n",
    "            \"midi_program_names\": info[\"midi_program_names\"],\n",
    "            \"track_path\": str(file_path),\n",
    "            \"prompt\": format_prompt(info[\"bpm\"], info[\"midi_program_names\"]),\n",
    "        }\n",
    "    return reference_condition_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcd = create_reference_condition_data(\n",
    "    condition_data,\n",
    "    slakh_reference_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate New Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select GPU\n",
    "torch.cuda.set_device(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/audiocraft/audiocraft/models/musicgen.py:83: UserWarning: MusicGen pretrained model relying on deprecated checkpoint mapping. Please use full pre-trained id instead: facebook/musicgen-small\n",
      "  warnings.warn(\n",
      "/data/matt/miniconda3/envs/audiocraft/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "# load in baseline model\n",
    "baseline = MusicGen.get_pretrained(\"small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_slakh = MusicGen.get_pretrained(checkpoints_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATED_AUDIO_DIR = Path(\"/data/matt/mg_generated_audio\")\n",
    "BASELINE_OUTPUT_DIR = GENERATED_AUDIO_DIR / \"baseline\"\n",
    "FINETUNE_OUTPUT_DIR = GENERATED_AUDIO_DIR / \"finetune\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _resample_and_overwrite(\n",
    "    audio_file: Path,\n",
    "    target_sr: Optional[int] = None,\n",
    ") -> None:\n",
    "    if target_sr is None:\n",
    "        return\n",
    "    y, sr = librosa.load(audio_file, sr=None)\n",
    "    audio = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
    "    if audio.ndim == 2:\n",
    "        audio = audio.T\n",
    "    # overwrite the file with the resampled audio\n",
    "    sf.write(audio_file, audio, samplerate=target_sr)\n",
    "\n",
    "\n",
    "def unconditional_generate_wrapper(\n",
    "    model: MusicGen,\n",
    "    duration: int = 16,\n",
    "    num_samples: int = 32,\n",
    "    output_dir: Path = BASELINE_OUTPUT_DIR,\n",
    "    batch_size: int = 4,\n",
    "    target_sr: Optional[int] = None,\n",
    "):\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    model.set_generation_params(duration=duration)\n",
    "    for i in tqdm(range(0, num_samples, batch_size)):\n",
    "        samples_in_this_batch = min(batch_size, num_samples - i)\n",
    "        batch = model.generate_unconditional(num_samples=samples_in_this_batch)\n",
    "        wavs = batch.cpu()\n",
    "        for j, wav in enumerate(wavs):\n",
    "            audio_write(\n",
    "                output_dir / f\"sample_{i + j}\",\n",
    "                wav,\n",
    "                model.sample_rate,\n",
    "                strategy=\"loudness\",\n",
    "            )\n",
    "            _resample_and_overwrite(\n",
    "                output_dir / f\"sample_{i + j}.wav\",\n",
    "                target_sr=target_sr,\n",
    "            )\n",
    "\n",
    "\n",
    "def conditional_generate_wrapper(\n",
    "    model: MusicGen,\n",
    "    prompts: dict[str, str],\n",
    "    duration: int = 16,\n",
    "    output_dir: Path = BASELINE_OUTPUT_DIR,\n",
    "    batch_size: int = 4,\n",
    "    target_sr: Optional[int] = None,\n",
    ") -> dict[str, dict[str, str]]:\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    model.set_generation_params(duration=duration)\n",
    "    prompt_id_pairs = list(prompts.items())\n",
    "    res = {}\n",
    "    for i in tqdm(range(0, len(prompt_id_pairs), batch_size)):\n",
    "        samples_in_this_batch = min(batch_size, len(prompt_id_pairs) - i)\n",
    "        batch = prompt_id_pairs[i : i + samples_in_this_batch]\n",
    "        prompts = []\n",
    "        ids = []\n",
    "        for track_id, prompt in batch:\n",
    "            prompts.append(prompt)\n",
    "            ids.append(track_id)\n",
    "        batch = model.generate(prompts)\n",
    "        wavs = batch.cpu()\n",
    "        for j, (wav, track_id) in enumerate(zip(wavs, ids)):\n",
    "            audio_write(\n",
    "                output_dir / f\"{track_id}\",\n",
    "                wav,\n",
    "                model.sample_rate,\n",
    "                strategy=\"loudness\",\n",
    "                loudness_compressor=True,\n",
    "            )\n",
    "            _resample_and_overwrite(\n",
    "                output_dir / f\"{track_id}.wav\",\n",
    "                target_sr=target_sr,\n",
    "            )\n",
    "            res[track_id] = {\n",
    "                \"prompt\": prompts[j],\n",
    "                \"generated_audio_file\": str(output_dir / f\"{track_id}.wav\"),\n",
    "            }\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate baseline\n",
    "unconditional_generate_wrapper(\n",
    "    baseline,\n",
    "    duration=16,\n",
    "    num_samples=32,\n",
    "    output_dir=BASELINE_OUTPUT_DIR / \"slakh_uncond_v2\",\n",
    "    batch_size=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]CLIPPING /data/matt/mg_finetune_output/v2/sample_0 happening with proba (a bit of clipping is okay): 0.0002851562458090484 maximum scale:  1.2295184135437012\n",
      "CLIPPING /data/matt/mg_finetune_output/v2/sample_2 happening with proba (a bit of clipping is okay): 7.031249697320163e-05 maximum scale:  1.1658837795257568\n",
      "CLIPPING /data/matt/mg_finetune_output/v2/sample_3 happening with proba (a bit of clipping is okay): 7.812500371073838e-06 maximum scale:  1.0617191791534424\n",
      " 12%|█▎        | 1/8 [00:24<02:54, 24.86s/it]CLIPPING /data/matt/mg_finetune_output/v2/sample_4 happening with proba (a bit of clipping is okay): 0.0006093750125728548 maximum scale:  1.3964048624038696\n",
      "CLIPPING /data/matt/mg_finetune_output/v2/sample_5 happening with proba (a bit of clipping is okay): 0.0003007812483701855 maximum scale:  1.2779303789138794\n",
      "CLIPPING /data/matt/mg_finetune_output/v2/sample_6 happening with proba (a bit of clipping is okay): 0.0003808593610301614 maximum scale:  1.34223473072052\n",
      "CLIPPING /data/matt/mg_finetune_output/v2/sample_7 happening with proba (a bit of clipping is okay): 0.0008613281534053385 maximum scale:  1.3610210418701172\n",
      " 25%|██▌       | 2/8 [00:48<02:25, 24.18s/it]CLIPPING /data/matt/mg_finetune_output/v2/sample_8 happening with proba (a bit of clipping is okay): 0.0011484374990686774 maximum scale:  1.6443496942520142\n",
      "CLIPPING /data/matt/mg_finetune_output/v2/sample_9 happening with proba (a bit of clipping is okay): 0.0019550782162696123 maximum scale:  1.5744054317474365\n",
      "CLIPPING /data/matt/mg_finetune_output/v2/sample_10 happening with proba (a bit of clipping is okay): 0.0009824219159781933 maximum scale:  1.4751429557800293\n",
      "CLIPPING /data/matt/mg_finetune_output/v2/sample_11 happening with proba (a bit of clipping is okay): 0.0003808593610301614 maximum scale:  1.4812337160110474\n",
      " 38%|███▊      | 3/8 [01:12<02:00, 24.05s/it]CLIPPING /data/matt/mg_finetune_output/v2/sample_12 happening with proba (a bit of clipping is okay): 0.00023437499476131052 maximum scale:  1.4597711563110352\n",
      "CLIPPING /data/matt/mg_finetune_output/v2/sample_13 happening with proba (a bit of clipping is okay): 0.003921874798834324 maximum scale:  1.5101863145828247\n",
      "CLIPPING /data/matt/mg_finetune_output/v2/sample_14 happening with proba (a bit of clipping is okay): 0.0009531250107102096 maximum scale:  1.2969774007797241\n",
      "CLIPPING /data/matt/mg_finetune_output/v2/sample_15 happening with proba (a bit of clipping is okay): 0.00041210936615243554 maximum scale:  1.4121075868606567\n",
      " 50%|█████     | 4/8 [01:36<01:35, 23.94s/it]CLIPPING /data/matt/mg_finetune_output/v2/sample_16 happening with proba (a bit of clipping is okay): 0.0007402343908324838 maximum scale:  1.3961281776428223\n",
      "CLIPPING /data/matt/mg_finetune_output/v2/sample_17 happening with proba (a bit of clipping is okay): 0.0016445312649011612 maximum scale:  1.4568589925765991\n",
      "CLIPPING /data/matt/mg_finetune_output/v2/sample_18 happening with proba (a bit of clipping is okay): 0.00036718748742714524 maximum scale:  1.3224071264266968\n",
      "CLIPPING /data/matt/mg_finetune_output/v2/sample_19 happening with proba (a bit of clipping is okay): 0.001687500043772161 maximum scale:  1.71322762966156\n",
      " 62%|██████▎   | 5/8 [01:59<01:11, 23.72s/it]CLIPPING /data/matt/mg_finetune_output/v2/sample_20 happening with proba (a bit of clipping is okay): 0.0009238281054422259 maximum scale:  1.375727653503418\n",
      "CLIPPING /data/matt/mg_finetune_output/v2/sample_21 happening with proba (a bit of clipping is okay): 0.0006874999962747097 maximum scale:  1.4241011142730713\n",
      "CLIPPING /data/matt/mg_finetune_output/v2/sample_22 happening with proba (a bit of clipping is okay): 3.320312680443749e-05 maximum scale:  1.121006727218628\n",
      "CLIPPING /data/matt/mg_finetune_output/v2/sample_23 happening with proba (a bit of clipping is okay): 0.00012304687697906047 maximum scale:  1.234642744064331\n",
      " 75%|███████▌  | 6/8 [02:23<00:47, 23.64s/it]CLIPPING /data/matt/mg_finetune_output/v2/sample_24 happening with proba (a bit of clipping is okay): 0.000863281253259629 maximum scale:  1.423060655593872\n",
      "CLIPPING /data/matt/mg_finetune_output/v2/sample_25 happening with proba (a bit of clipping is okay): 0.0005507812602445483 maximum scale:  1.485440969467163\n",
      "CLIPPING /data/matt/mg_finetune_output/v2/sample_26 happening with proba (a bit of clipping is okay): 0.000470703118480742 maximum scale:  1.3101027011871338\n",
      "CLIPPING /data/matt/mg_finetune_output/v2/sample_27 happening with proba (a bit of clipping is okay): 0.0008593749953433871 maximum scale:  1.3670436143875122\n",
      " 88%|████████▊ | 7/8 [02:46<00:23, 23.74s/it]CLIPPING /data/matt/mg_finetune_output/v2/sample_28 happening with proba (a bit of clipping is okay): 2.5390625523868948e-05 maximum scale:  1.1133254766464233\n",
      "CLIPPING /data/matt/mg_finetune_output/v2/sample_29 happening with proba (a bit of clipping is okay): 0.00019140624499414116 maximum scale:  1.3987557888031006\n",
      "CLIPPING /data/matt/mg_finetune_output/v2/sample_30 happening with proba (a bit of clipping is okay): 0.00023437499476131052 maximum scale:  1.26941978931427\n",
      "CLIPPING /data/matt/mg_finetune_output/v2/sample_31 happening with proba (a bit of clipping is okay): 0.00024609375395812094 maximum scale:  1.3623918294906616\n",
      "100%|██████████| 8/8 [03:11<00:00, 24.00s/it]\n"
     ]
    }
   ],
   "source": [
    "# generate unconditional\n",
    "unconditional_generate_wrapper(\n",
    "    ft_slakh,\n",
    "    duration=16,\n",
    "    num_samples=32,\n",
    "    output_dir=FINETUNE_OUTPUT_DIR / \"slakh_uncond_v2\",\n",
    "    batch_size=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example 2: text guided generation\n",
    "\n",
    "# wavs = musicgen.generate([\n",
    "#     'disco',\n",
    "#     'slide guitar bluegrass',\n",
    "#     'breakbeat, amen break',\n",
    "#     'epic orchestral strings'\n",
    "# ])\n",
    "\n",
    "# # save and display generated audio\n",
    "# for idx, one_wav in enumerate(wavs):\n",
    "#     audio_write(f'{idx}', one_wav.cpu(), musicgen.sample_rate, strategy=\"loudness\", loudness_compressor=True)\n",
    "#     ipd.display(ipd.Audio(one_wav.cpu(), rate=32000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcd_prompts = {track_id: v[\"prompt\"] for track_id, v in rcd.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [03:16<00:00, 24.51s/it]\n"
     ]
    }
   ],
   "source": [
    "conditional_generate_wrapper(\n",
    "    ft_slakh,\n",
    "    rcd_prompts,\n",
    "    duration=16,\n",
    "    output_dir=FINETUNE_OUTPUT_DIR / \"slakh_cond_v2\",\n",
    "    batch_size=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [03:12<00:00, 24.10s/it]\n"
     ]
    }
   ],
   "source": [
    "conditional_generate_wrapper(\n",
    "    baseline,\n",
    "    rcd_prompts,\n",
    "    duration=16,\n",
    "    output_dir=BASELINE_OUTPUT_DIR / \"slakh_cond_v2\",\n",
    "    batch_size=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_condition_data_with_output_audio_file_path(\n",
    "    condition_data: dict[str, dict[str, Any]],\n",
    "    output_dir: Path,\n",
    "):\n",
    "    res = {}\n",
    "    for track_id, info in condition_data.items():\n",
    "        target_path = output_dir / f\"{track_id}.wav\"\n",
    "        if not target_path.exists():\n",
    "            print(f\"Warning: {target_path} does not exist.\")\n",
    "            continue\n",
    "        res[track_id] = {\n",
    "            \"prompt\": info[\"prompt\"],\n",
    "            \"bpm\": info[\"bpm\"],\n",
    "            \"midi_program_names\": info[\"midi_program_names\"],\n",
    "            \"audio_file_path\": str(target_path),\n",
    "        }\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "clap_input_baseline = combine_condition_data_with_output_audio_file_path(\n",
    "    rcd,\n",
    "    BASELINE_OUTPUT_DIR / \"slakh_cond_v2\",\n",
    ")\n",
    "\n",
    "clap_input_finetune = combine_condition_data_with_output_audio_file_path(\n",
    "    rcd,\n",
    "    FINETUNE_OUTPUT_DIR / \"slakh_cond_v2\",\n",
    ")\n",
    "\n",
    "with open(PROJECT_DATA_DIR / \"clap_input_baseline.json\", \"w\") as f:\n",
    "    json.dump(clap_input_baseline, f, indent=4)\n",
    "\n",
    "with open(PROJECT_DATA_DIR / \"clap_input_finetune.json\", \"w\") as f:\n",
    "    json.dump(clap_input_finetune, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Caps Conditional Generation Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_caps_wavs_dir = Path(\"/data/matt/music_caps/wavs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"google/MusicCaps\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0Gj8-vB1q4\n"
     ]
    }
   ],
   "source": [
    "dummy_id = dataset[0][\"ytid\"]\n",
    "print(dummy_id)\n",
    "file_path = music_caps_wavs_dir / f\"{dummy_id}.wav\"\n",
    "file_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220500,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, sr = librosa.load(file_path)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUSIC_CAPS_SR = 16000\n",
    "MUSIC_CAPS_DURATION = 10\n",
    "\n",
    "\n",
    "def prep_music_caps(\n",
    "    dataset: Dataset,\n",
    "    wav_dir: Path = music_caps_wavs_dir,\n",
    "    output_dir: Path = music_caps_wavs_dir.parent / \"audiocraft\",\n",
    "    train_split_size: int = 2048,\n",
    "    test_split_size: int = 32,\n",
    ") -> None:\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    dataset.shuffle(seed=42)  # Shuffle the dataset for randomness\n",
    "    train_dataset = dataset.select(range(train_split_size))\n",
    "    test_dataset = dataset.select(\n",
    "        range(train_split_size, train_split_size + test_split_size)\n",
    "    )\n",
    "    prep_music_caps_split(train_dataset, \"train\", wav_dir, output_dir)\n",
    "    prep_music_caps_split(test_dataset, \"test\", wav_dir, output_dir)\n",
    "\n",
    "\n",
    "def prep_music_caps_split(\n",
    "    dataset: Dataset,\n",
    "    split: str,\n",
    "    wav_dir: Path = music_caps_wavs_dir,\n",
    "    output_dir: Path = music_caps_wavs_dir.parent / \"audiocraft\",\n",
    ") -> None:\n",
    "    split_data = []\n",
    "    for entry in tqdm(dataset):\n",
    "        ytid = entry[\"ytid\"]\n",
    "        wav_path = wav_dir / f\"{ytid}.wav\"\n",
    "        if not wav_path.exists():\n",
    "            print(f\"Warning: {wav_path} does not exist.\")\n",
    "            continue\n",
    "\n",
    "        # use librosa to estimate key\n",
    "        y, sr = librosa.load(wav_path, sr=None)\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        key = np.argmax(np.sum(chroma, axis=1))\n",
    "\n",
    "        ac_entry = {\n",
    "            \"key\": str(key),\n",
    "            \"sample_rate\": MUSIC_CAPS_SR,\n",
    "            \"file_extension\": \"wav\",\n",
    "            \"description\": entry[\"caption\"],\n",
    "            \"keywords\": \"\",\n",
    "            \"duration\": MUSIC_CAPS_DURATION,\n",
    "            \"bpm\": \"\",\n",
    "            \"genre\": \"\",\n",
    "            \"title\": \"\",\n",
    "            \"name\": \"\",\n",
    "            \"instrument\": \"\",\n",
    "            \"moods\": [],\n",
    "            \"path\": str(wav_path),\n",
    "        }\n",
    "        split_data.append(ac_entry)\n",
    "    split_dir = output_dir / split\n",
    "    split_dir.mkdir(parents=True, exist_ok=True)\n",
    "    write_jsonl(split_data, output_dir / split / \"data.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 147/2048 [00:06<01:22, 23.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /data/matt/music_caps/wavs/0J_2K1Gvruk.wav does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 202/2048 [00:08<00:55, 33.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /data/matt/music_caps/wavs/0fqtA_ZBn_8.wav does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 397/2048 [00:17<01:08, 24.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /data/matt/music_caps/wavs/2dyxjGTXSpA.wav does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 724/2048 [00:31<00:51, 25.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /data/matt/music_caps/wavs/63rqIYPHvlc.wav does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 821/2048 [00:35<00:47, 26.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /data/matt/music_caps/wavs/7B1OAtD_VIA.wav does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 855/2048 [00:36<00:51, 23.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /data/matt/music_caps/wavs/7WZwlOrRELI.wav does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 1157/2048 [00:48<00:35, 25.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /data/matt/music_caps/wavs/Ah_aYOGnQ_I.wav does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 1210/2048 [00:50<00:33, 25.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /data/matt/music_caps/wavs/B7iRvj8y9aU.wav does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 1282/2048 [00:53<00:31, 24.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /data/matt/music_caps/wavs/BiQik0xsWxk.wav does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 1336/2048 [00:56<00:31, 22.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /data/matt/music_caps/wavs/C7OIuhWSbjU.wav does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 1745/2048 [01:12<00:14, 21.10it/s]/data/matt/miniconda3/envs/audiocraft/lib/python3.9/site-packages/librosa/core/pitch.py:103: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n",
      " 87%|████████▋ | 1783/2048 [01:14<00:09, 26.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /data/matt/music_caps/wavs/HAHn_zB47ig.wav does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1924/2048 [01:20<00:04, 25.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /data/matt/music_caps/wavs/IbJh1xeBFcI.wav does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [01:25<00:00, 23.92it/s]\n",
      "100%|██████████| 32/32 [00:01<00:00, 21.60it/s]\n"
     ]
    }
   ],
   "source": [
    "prep_music_caps(\n",
    "    dataset,\n",
    "    wav_dir=music_caps_wavs_dir,\n",
    "    output_dir=music_caps_wavs_dir.parent / \"audiocraft\",\n",
    "    train_split_size=2048,\n",
    "    test_split_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run training with dora framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_caps_train_command = \"\"\"\\\n",
    "TMPDIR=/data/matt/tmp CUDA_VISIBLE_DEVICES=4,5,6,7 dora -P audiocraft run \\\n",
    "  solver=musicgen/musicgen_base_32khz \\\n",
    "  +model.lm.model_scale=small \\\n",
    "  continue_from=//pretrained/facebook/musicgen-small \\\n",
    "  conditioner=text2music \\\n",
    "  dset=audio/music_caps \\\n",
    "  dataset.num_workers=4 \\\n",
    "  dataset.valid.num_samples=32 \\\n",
    "  dataset.batch_size=4 \\\n",
    "  schedule.cosine.warmup=8 \\\n",
    "  optim.optimizer=adamw \\\n",
    "  optim.lr=1e-4 \\\n",
    "  optim.epochs=3 \\\n",
    "  optim.updates_per_epoch=1000 \\\n",
    "  optim.adam.weight_decay=0.01 \\\n",
    "  generate.lm.prompted_samples=False \\\n",
    "  generate.lm.gen_gt_samples=True\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{music_caps_train_command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export checkpoint\n",
    "MC_V1_CKPT_DIR = CKPT_DIR / \"mc_v1\"\n",
    "MC_V1_SIG = \"40b4c24f\"\n",
    "export_model_checkpoint(MC_V1_SIG, ckpt_d=MC_V1_CKPT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate new samples from MusicCaps fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/audiocraft/audiocraft/models/musicgen.py:83: UserWarning: MusicGen pretrained model relying on deprecated checkpoint mapping. Please use full pre-trained id instead: facebook/musicgen-small\n",
      "  warnings.warn(\n",
      "/data/matt/miniconda3/envs/audiocraft/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(5)\n",
    "baseline_mc = MusicGen.get_pretrained(\"small\")\n",
    "mc_ckpt = MC_V1_CKPT_DIR\n",
    "ft_mc = MusicGen.get_pretrained(mc_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_music_cap_test_prompts():\n",
    "    music_cap_prompts = {}\n",
    "    mc_test_jsonl_path = music_caps_wavs_dir.parent / \"audiocraft/test/data.jsonl\"\n",
    "    lines = mc_test_jsonl_path.read_text().splitlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        entry = json.loads(line)\n",
    "        id_ = f\"mc_test{i}\"\n",
    "        music_cap_prompts[id_] = entry[\"description\"]\n",
    "    return music_cap_prompts\n",
    "\n",
    "\n",
    "music_cap_prompts = get_music_cap_test_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:14<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconditional_generate_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaseline_mc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmusic_cap_prompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMUSIC_CAPS_DURATION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBASELINE_OUTPUT_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmc_cond_v1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_sr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mMUSIC_CAPS_SR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[115], line 77\u001b[0m, in \u001b[0;36mconditional_generate_wrapper\u001b[0;34m(model, prompts, duration, output_dir, batch_size, target_sr)\u001b[0m\n\u001b[1;32m     65\u001b[0m         audio_write(\n\u001b[1;32m     66\u001b[0m             output_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrack_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     67\u001b[0m             wav,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m             loudness_compressor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     71\u001b[0m         )\n\u001b[1;32m     72\u001b[0m         _resample_and_overwrite(\n\u001b[1;32m     73\u001b[0m             output_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrack_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     74\u001b[0m             target_sr\u001b[38;5;241m=\u001b[39mtarget_sr,\n\u001b[1;32m     75\u001b[0m         )\n\u001b[1;32m     76\u001b[0m         res[track_id] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m---> 77\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mprompts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrack_id\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[1;32m     78\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_audio_file\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(output_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrack_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     79\u001b[0m         }\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "conditional_generate_wrapper(\n",
    "    model=baseline_mc,\n",
    "    prompts=music_cap_prompts,\n",
    "    duration=MUSIC_CAPS_DURATION,\n",
    "    output_dir=BASELINE_OUTPUT_DIR / \"mc_cond_v1\",\n",
    "    target_sr=MUSIC_CAPS_SR,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audiocraft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
